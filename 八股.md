MySQL

请讲讲mysql的sql优化技巧有哪些？

避免使用select *，用union all代替union，小表驱动大表，用连接查询代替子查询， join的表不宜过多，添加索引和索引优化

 

说说mysql的回表查询？

MySQL 的回表查询是一种在查询过程中需要从索引和数据文件中多次获取数据的操作，当查询语句使用了覆盖索引时，MySQL 可以直接从索引中获取数据，而无需访问数据文件。但如果查询的列不都包含在索引中，就需要先通过索引找到对应的主键值，然后再根据主键值去数据文件中查找完整的行数据，这个过程就叫做回表查询。

回表查询会增加查询的成本，因为它需要额外的 I/O 操作来从数据文件中获取数据。如果回表次数过多，可能会导致查询性能下降。特别是在处理大量数据时，回表操作可能会成为性能瓶颈。不过，如果索引设计合理，回表查询的次数可以得到有效控制，从而保证查询性能。例如，尽量使用覆盖索引，避免不必要的回表查询；或者根据查询条件和业务需求，合理设计联合索引，将经常一起查询的列包含在索引中，减少回表的可能性。

 

B+树和二叉树的区别? （这块删掉，如果问了的话就说不太清楚区别，但了解b+树，然后把下面那个问题的内容说出来）

 

 

为什么mysql索引要用B+树？

· B + 树的节点可以存储多个键值对和指针，这样可以将更多的信息存储在一个节点中，减少磁盘 I/O 次数。每次读取一个节点，就能获取到多个键值对的信息，从而提高查询效率。

· 同时B + 树的叶子节点是按照键值的顺序排列的，并且通过链表相连。这使得范围查询变得非常高效，只需要从链表的一端开始，按照顺序遍历即可获取到指定范围内的所有数据。

· 以及，B + 树是一种平衡树，查询性能稳定。

mysql索引的数据结构是怎样的？

MySQL 索引的数据结构主要采用 B + 树，B+树是一种专为数据库系统优化的多路平衡搜索树，每个节点可以有多个子节点，所有数据都存储在叶子节点，非叶子节点仅存储索引键和指针，叶子节点之间通过指针相连，形成有序链表。

B+树的平衡特性保证了查询效率的稳定性，多路设计减少了树的高度，降低磁盘 I/O 次数，叶子节点的有序链表支持高效的范围查询。

mysql中mvcc是什么？

Mvcc是多版本并发控制，一种数据库并发控制方法，通过维护数据的多个版本来实现读写操作的并行执行。它允许读操作不加锁，避免了读写之间的阻塞，从而提高了系统的并发性能。多版本并发控制作为一种有效的并发控制机制，被广泛应用于现代关系型数据库系统中，如InnoDB 存储引擎。

MVCC 的主要目的是实现高并发下的数据一致性与隔离性。它通过为每个事务提供数据的一个“快照”，确保事务在其执行期间看到的数据是一致的，从而避免了幻读、不可重复读等现象。此外，MVCC 还减少了锁的使用，降低了锁竞争，提高了系统的吞吐量。

 

 

Mysql如何实现事务？

MySQL 的事务机制主要通过 InnoDB 存储引擎实现，其核心是确保数据操作满足 ACID 特性。

原子性的实现依赖于 undo 日志，当事务需要回滚时，undo 日志会记录数据修改前的状态，从而将数据恢复到初始状态；

一致性则通过原子性、隔离性和持久性共同保障，同时结合数据库的约束条件来确保数据完整性。

隔离性的实现较为复杂，InnoDB 同时采用锁机制和多版本并发控制MVCC，锁机制包括共享锁、排他锁以及间隙锁，而MVCC则通过为每行数据维护版本号和undo日志链，让不同事务能读取到一致的数据视图。

持久性的保障来自 redo 日志，采用预写式日志策略，事务提交时先将操作记录写入 redo 日志，确保即使数据库崩溃也能通过日志恢复数据。

 

 

 

Mysql超大分页如何处理？

### 可以利用覆盖索引，确保查询的字段全部包含在索引中，避免回表查询。

### 可以使用书签分页，通过记录上次查询的最后一条记录的主键或索引值，直接定位到下一页的起始位置，避免扫描大量无关数据，适用于api接口的分页场景，如社交媒体的滚动加载。可以提前分表存储，将数据按特定规则如时间预先分表存储，查询时直接定位到对应表，减少查询时的表数据总量，适用于数据有明显时间或范围划分的场景，如日志系统。

以及对于需要遍历全量数据如数据导出的场景，可以使用游标逐批处理。还有要避免使用 limit 和offset，有可能导致全表扫描和占据过多临时内存与磁盘空间。

 

请讲讲mysql事务的四大特性是哪些？

　　原子性，指事务包含的所有操作要么全部成功，要么全部失败回滚，因此事务的操作如果成功就必须要完全应用到数据库，如果操作失败则不能对数据库有任何影响。

一致性，指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。

　　隔离性，当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。

持久性，指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。

 

 什么是脏读、不可重复读、幻读？

脏读：事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据。

不可重复读：事务 A 多次读取同一数据，事务 B 在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果不一致。

幻读：事务A对表中的数据进行了修改，涉及到表中的全部行。同时，事务B也修改这个表中的数据，向表中插入一行新数据。那么，事务A发现表中还有自己没有修改的行，就好象发生了幻觉一样。

 

 

讲讲mysql事务的四种隔离级别以及对应会遇到的问题？

读未提交，能读到未提交的数据。会出现脏读、不可重复读、幻读。

 

读已提交，读已提交的数据。会出现不可重复读和幻读。

 

可重复读，mysql默认的事务隔离级别，查询的都是事务开始时的数据。只会出现幻读。

 

串行读，完全串行化读，每次都会锁表，读写互相阻塞。最高隔离级别，不会出现脏读，不可重复读，幻读。但会大大影响系统的性能，一般不用。

 

 

 

 

mysql的索引是什么？有哪些索引？

 普通索引

最基本的索引类型，它没有任何限制，其主要目的就是加快对数据的访问速度。

唯一索引

要求索引列中的值必须唯一，即不允许出现重复值，但可以有 NULL 值。这种索引常用于确保数据的唯一性，同时也能提高查询效率。

主键索引

一种特殊的唯一索引，一个表只能有一个主键索引，并且主键索引不允许有空值。它通常用于唯一标识表中的每一行数据，是表中记录的唯一标识符。

全文索引

主要用于在文本类型的列中进行全文搜索，例如 CHAR、VARCHAR 或 TEXT 类型的列。它可以对文本内容进行分词处理，然后根据关键词进行快速搜索。

空间索引

用于对空间数据类型的列进行索引。它可以加速空间数据的查询，例如查找某个区域内的地理坐标点。

复合索引

指在多个列上创建的索引。使用复合索引时，MySQL 可以根据索引中的列顺序依次进行查找，因此在设计复合索引时，列的顺序非常重要。

以及并非一种单独索引类型而是一种数据存储方式的聚簇索引，特点是表数据会按照主键的顺序进行物理存储。由主键索引实现，因此每个表只能有一个聚簇索引。

 

说说索引怎样合理设置？

频繁用于查询条件、join连接操作、排序、分组、唯一约束或主键的列应该设置索引，小表不应该设置索引，避免冗余索引，控制索引数量，对长字符串使用前缀索引。

 

讲一下索引的失效场景？

查询条件不满足最左前缀原则，在索引列上使用函数或表达式，使用OR连接条件时部分列无索引，复合索引中其中一列进行了范围查询，模糊查询以通配符开头，强制索引失效

 

mysql有哪些存储引擎？对比特点是什么？

InnoDB，有事务支持，InnoDB 是 MySQL 默认的存储引擎，它支持事务处理，遵循 原子性、一致性、隔离性、持久性原则。

支持外键约束，这有助于维护数据的参照完整性。当一个表中的数据依赖于另一个表中的数据时，外键约束可以确保数据的一致性。

采用行级锁，在并发访问时可以提高性能。当多个事务同时操作不同行的数据时，行级锁可以减少锁的竞争，提高并发处理能力。

使用聚簇索引，数据行按照主键的顺序存储在磁盘上。这使得基于主键的查询非常高效，因为可以直接定位到数据行所在的物理位置。

适用于对事务处理要求较高、数据一致性要求严格、并发访问频繁的应用。

另一个MyISAM不支持事务处理，这意味着它不能保证一组操作的原子性和一致性。在进行数据修改时，如果出现错误，无法回滚到操作前的状态。

也不支持外键约束，因此无法通过外键来维护数据的参照完整性。

采用表级锁，在并发访问时性能较差。当一个事务对表进行写操作时，会锁定整个表，其他事务必须等待该锁释放才能进行操作。

支持全文索引，对于文本搜索功能有较好的支持。

适用于对事务和外键要求不高，以读操作和插入操作为主的应用。

 

对Mysql的锁有了解吗？

按锁粒度分类有全局锁、表级锁、行级锁，全局锁对整个数据库实例加锁，表级锁有直接锁定整张表的表锁，表明某个事务正在锁定表的某一行或准备锁定的意向锁，行锁有允许事务读取一行数据的共享锁，允许事务更新或删除一行数据的排他锁，按理念划分有假设冲突总会发生，直接加锁的悲观锁和假设数据在读取和更新期间不会发生冲突，因此不直接加锁，而是在更新时验证数据是否被其他事务修改过。如果发现冲突，则回滚重试的乐观锁。

 

你对哪些设计模式有所了解，讲讲这些设计模式？（设计模式只有这一个问题，因此放到mysql下）

工厂设计模式，提供了一种创建对象的方式，通过一个工厂类来负责对象的创建过程，而不是在客户端代码中直接使用 new 关键字来实例化对象。这样做的好处是，当对象的创建逻辑发生变化时，只需要修改工厂类，而不会影响到使用这些对象的客户端代码。

优点

解耦对象的创建和使用，将对象的创建逻辑封装在工厂类中，客户端只需要使用对象，不需要关心对象的创建过程，降低了代码的耦合度。

提高可维护性和可扩展性，当对象的创建逻辑发生变化时，只需要修改工厂类，而不会影响到客户端代码。同时，添加新的产品时，只需要扩展工厂类或创建新的具体工厂类。

符合开闭原则，工厂方法模式和抽象工厂模式遵循开闭原则，对扩展开放，对修改关闭。

缺点

增加代码复杂度，随着工厂模式的使用，类的数量会增加，导致系统复杂度上升。

理解难度较大，对于初学者来说，理解工厂模式的概念和实现可能有一定的难度。

 

建造者模式，在软件开发中，有些对象的创建过程较为复杂，包含多个步骤，并且可能有多种不同的配置组合，而该模式将对象的创建步骤进行封装，通过一个指挥者来控制这些步骤的执行顺序，从而可以创建出不同表示的对象，而客户端只需要指定要创建的对象类型，无需关心具体的创建过程。

优点

封装性好，将对象的创建过程封装在具体建造者中，客户端无需了解对象的具体创建细节，降低了代码的耦合度。

可扩展性强，可以很方便地添加新的具体建造者来创建不同表示的对象，符合开闭原则。

构建过程可控：指挥者可以控制构建过程的顺序，确保对象的构建步骤按照正确的顺序执行。

缺点

代码复杂度增加，由于引入了多个类，代码量会增加，结构变得相对复杂。

适用范围有限，建造者模式适用于创建复杂对象，如果对象的构建过程简单，使用该模式会显得冗余。

 

责任链模式，多个处理者组成一条链，每个处理者都有机会处理请求。当客户端发出一个请求时，该请求会从链的头部开始传递，依次经过每个处理者。每个处理者在接收到请求后，会判断自己是否能够处理该请求，如果可以，则进行处理；如果不能，则将请求传递给链中的下一个处理者，直到请求被处理或者到达链的末尾。

优点

降低耦合度，请求发送者和接收者之间解耦，发送者不需要知道哪个处理者会处理请求，只需要将请求发送到链上即可。

可扩展性强，可以动态地增加或删除处理者，或者改变处理者的顺序，而不会影响客户端代码。

灵活性高，可以根据实际需求灵活地组织处理者链，满足不同的业务逻辑。

缺点

请求可能得不到处理，如果处理者链配置不当，可能会导致请求在链中传递到末尾都没有被处理。

调试困难，由于请求的处理过程分散在多个处理者中，当出现问题时，调试和排查错误可能会比较困难。

性能问题，如果处理者链过长，请求的传递会消耗一定的时间和资源，影响系统性能。

 

 

 

 

 

 

 

Redis

讲讲redis的分布式锁？

Redis 分布式锁的核心原理基于 Redis 的原子操作。Redis 是单线程执行命令的，这保证了单个命令执行的原子性。当多个客户端尝试获取同一把锁时，通过在 Redis 中设置一个具有特定键名的键值对来表示锁的状态。如果设置成功，则表示获取到了锁；如果设置失败，则表示锁已被其他客户端持有。

常见实现方式有

使用 SETNX 命令，SETNX是 Redis 的一个原子命令，用于在键不存在时设置键的值。如果键已经存在，SETNX 命令将不做任何操作并返回 0；如果键不存在，则设置键的值并返回 1。

使用 SET 命令，Redis 2.6.12 版本及以后，SET 命令支持了 NX和 EX选项，可以原子性地设置键的值并设置过期时间。这样即使持有锁的客户端出现异常，锁也会在过期时间后自动释放。

存在的问题有

锁过期问题

如果业务逻辑的执行时间超过了锁的过期时间，可能会导致多个客户端同时持有锁，从而引发并发问题。

解决方案是可以使用锁续约机制，在业务逻辑执行过程中，启动一个定时任务，定期检查锁是否还存在，如果存在则延长锁的过期时间。

误释放锁问题

如果客户端 A 获取到锁后，由于某些原因执行时间过长，锁过期自动释放，此时客户端 B 获取到了锁。而客户端 A 在执行完业务逻辑后释放锁，会错误地释放客户端 B 的锁。

解决方案是在释放锁时，需要先检查锁的值是否是自己设置的那个值，如果是则释放，否则不释放。可以使用 Lua 脚本来保证检查和删除操作的原子性。

集群环境下的锁问题

在 Redis 集群环境中，由于数据可能分布在不同的节点上，使用单个 Redis 节点实现的分布式锁可能会出现问题，如主从切换时锁丢失。

解决方案是可以使用 Redlock 算法，该算法需要在多个独立的 Redis 节点上获取锁，只有当在大多数节点上都成功获取到锁时，才认为获取锁成功。不过 Redlock 算法也存在一些争议，使用时需要根据具体场景权衡。

 

redis有哪些数据结构？

字符串， Redis 中最基本的数据结构，一个键对应一个字符串值，它可以存储多种类型的数据，如文本、整数、二进制数据等，并且最大能存储 512MB 的数据。

哈希，一个键值对的集合，类似于 Python 中的字典。它适合存储对象，其中每个字段都有一个关联的值，并且可以独立地对这些字段进行操作。

列表，一个有序的字符串元素集合，它基于双向链表实现，这意味着可以在列表的两端快速地进行插入和删除操作。

集合，一个无序且唯一的字符串元素集合，不允许有重复的成员。它基于哈希表实现，所以添加、删除和查找元素的时间复杂度都是 O (1)。

有序集合，一种特殊的集合，它在集合的基础上为每个元素关联了一个分数，元素按照分数从小到大排序。如果分数相同，则按照元素的字典序排序。它使用跳跃表和哈希表来实现，保证了插入、删除和查找操作的时间复杂度为 O (log N)。

位图，不是一种实际的数据类型，而是基于字符串类型实现的一种位操作方式。它可以将字符串看作是一个由二进制位组成的数组，每个位可以存储 0 或 1。

HyperLogLog，一种用于估计集合中唯一元素数量的概率性数据结构。它只需要使用固定大小的内存，就可以对非常大的数据集进行基数估计，误差率在 0.81% 左右。

地理空间索引，用于存储地理位置信息，并支持对这些位置进行各种地理空间查询，如范围查询、距离计算等。它基于有序集合实现，将地理位置的经纬度编码为一个有序集合的分数。

 

redis 速度快的原因？

· Redis 将所有数据都存储在内存中，内存的读写速度远远快于硬盘等传统存储介质。

· 采用了多种高效的数据结构，如字符串、哈希、列表、集合、有序集合等，能够快速地进行数据的插入、删除、查找和更新操作。

· 且使用单线程来处理所有的客户端请求，避免了多线程环境下的线程切换和锁竞争开销。

· 同时采用了非阻塞的 I/O 模型，使用事件驱动机制来处理多个客户端的连接和请求。它通过多路复用技术可以同时监听多个套接字的事件，当有事件发生时才进行处理，能够同时处理大量的客户端请求。

· 以及网络通信架构经过了精心优化，它采用了简洁的请求 - 响应协议，减少了网络传输的开销和复杂性。

· 同时，Redis 还支持管道功能，客户端可以将多个命令一次性发送给服务器，服务器依次执行这些命令并将结果一次性返回给客户端，这样可以减少网络往返次数，提高数据传输效率。

 

讲讲redis 的IO多路复用是怎样的？

Redis使用 I/O 多路复用函数来监控多个文件描述符的状态变化，这些文件描述符代表了与客户端的连接、网络套接字或其他 I/O 资源。

服务器进程运行在一个事件循环中，在每次循环迭代时，会调用 I/O 多路复用函数，该函数会阻塞等待，直到有一个或多个文件描述符上有事件发生。当有事件发生时，函数返回，Redis 会根据发生的事件类型来执行相应的处理逻辑，例如读取客户端发送的命令、向客户端发送响应数据等。

通过 IO 多路复用，Redis 可以用一个线程处理多个客户端连接的 I/O 操作，而无需为每个连接创建一个单独的线程。这大大提高了服务器的并发处理能力，能够同时处理大量的客户端请求，节省了大量的系统资源，如内存和 CPU 时间。

以及由于 Redis 能够及时响应发生在各个文件描述符上的事件，不会因为某个连接的阻塞而影响其他连接的处理，所以可以实现低延迟的 I/O 操作。

 

 

 

讲讲redis的事务？

Redis 事务允许用户在一个步骤中执行多个命令。通过将多个命令组合成一个事务，用户可以确保这些命令作为一个不可分割的单元被执行，避免了在执行过程中被其他客户端的操作干扰，从而实现对数据的一致性操作。

主要通过几个命令来实现

MULTI，用于开启一个事务，之后输入的命令不会立即执行，而是会被放入一个队列中。

EXEC，执行事务队列中的所有命令。当执行 EXEC 命令时，Redis 会按照命令入队的顺序依次执行队列中的所有命令，并将执行结果返回给客户端。

DISCARD，取消当前事务，清空事务队列。

WATCH，用于监视一个或多个键。如果在事务执行之前，被监视的键被其他客户端修改了，那么整个事务将会被取消，EXEC 命令将返回 nil。

有几个特性

原子性，在 Redis 事务中，要么所有命令都执行，要么所有命令都不执行。当执行 EXEC 命令时，Redis 会将事务队列中的所有命令一次性执行，在执行过程中不会被其他客户端的命令打断。

顺序性，事务队列中的命令会按照入队的顺序依次执行，保证了操作的顺序性。

局限性在于

不支持回滚，与传统数据库事务不同，Redis 事务不支持回滚。如果事务中的某个命令执行失败，Redis 不会回滚之前已经执行的命令，也不会停止执行后续的命令。

以及在 Redis 集群环境下，由于数据分布在不同的节点上，事务的原子性可能无法得到保证。

 

 

 

 

 

讲讲redis的持久化策略？

Redis的持久化策略有RDB和AOF以及混合持久化。

其中RDB 持久化是将 Redis 在某个时间点上的内存数据快照保存到磁盘上的一个二进制文件。可以通过手动执行 SAVE 或 BGSAVE 命令，或者配置定期执行快照操作来触发 RDB 持久化。

而AOF 持久化是将 Redis 执行的所有写命令追加到一个日志文件中。当 Redis 重启时，会重新执行 AOF 文件中的所有命令来恢复数据。随着 Redis 不断执行写命令，AOF 文件会越来越大，为了避免 AOF 文件过大，Redis 提供了 AOF 重写机制。AOF 重写会创建一个新的 AOF 文件，将当前内存中的数据以最小的命令集合重新写入新文件，从而减小 AOF 文件的大小。可以通过手动执行 BGREWRITEAOF 命令或配置自动重写来触发 AOF 重写。

在Redis 4.0中引入了混合持久化机制，结合了 RDB 和 AOF 的优点。在进行 AOF 重写时，Redis 会将当前内存中的数据以 RDB 格式写入 AOF 文件的开头，然后再将重写后的增量写命令以 AOF 格式追加到文件末尾。

其中RDB文件体积小，恢复速度快，对性能影响小，但数据安全性低，而AOF数据安全性高，日志文件可读性强，但文件体积大且恢复速度慢，混合持久化先加载 RDB 部分，再执行 AOF 部分的命令，既保证了数据恢复速度，又提高了数据安全性。

 

 

 

 

请说说redis的主从复制原理？

主从复制的工作流程先是从节点启动，当从节点启动时，它会根据配置信息向主节点发送连接请求，请求建立复制连接。

如果主节点设置了密码，从节点在连接时需要提供正确的密码进行身份验证。

请求通过后从节点与主节点之间建立一个 TCP 连接，用于后续的数据同步和命令传输。

然后从节点向主节点发送 PSYNC 命令，请求进行数据同步。该命令会携带从节点当前的复制偏移量和主节点的运行ID。

主节点接收到 PSYNC 命令后，会根据从节点提供的运行ID和复制偏移量判断是否可以进行增量同步。如果从节点提供的运行ID和主节点运行ID一致且复制偏移差距较大则主节点会开始执行全量同步流程。

主节点执行 BGSAVE 命令，在后台生成一个 RDB 文件，该文件包含了主节点当前的所有数据。

然后将生成的 RDB 文件发送给从节点。在发送 RDB 文件的过程中，主节点会将新接收到的写命令缓存在内存中。

从节点接收到 RDB 文件后，会先清空自己的内存数据，然后将 RDB 文件中的数据加载到内存中。

主节点在 RDB 文件发送完成后，会将缓存的写命令发送给从节点，从节点执行这些写命令，以保证数据的一致性。

如果从节点提供的运行ID和主节点运行ID一致且复制偏移差距较小则主节点会开始执行增量同步流程。

主节点将从节点复制偏移量之后的所有写命令发送给从节点，从节点执行这些写命令，从而实现数据的同步。

在完成同步阶段后，主从节点进入命令传播阶段。在这个阶段，主节点会将新接收到的写命令实时地发送给从节点，从节点接收到这些命令后会执行，以保证主从节点的数据一致性。

同时为了确保主从节点之间的连接正常，Redis 在主从复制过程中引入了心跳机制。

从节点每隔一段时间向主节点发送带有从节点当前偏移量的命令，主节点可以根据这个偏移量判断从节点是否正常接收数据，以及主从节点之间的数据差距。

主节点也会定期向从节点发送 PING 命令，检查从节点的连接状态。

 

 

 

 

 

你对redis的缓存淘汰策略有哪些了解？

有以下几个，从设置了过期时间的键中，移除最近最少使用的键。Redis 会维护一个近似的 LRU 算法，通过对每个键记录一个时间戳，在需要淘汰数据时，优先选择时间戳最旧的键进行删除。

从所有键中，移除最近最少使用的键。无论键是否设置了过期时间，只要它是最久未被使用的，就可能被淘汰。

从设置了过期时间的键中，移除最不经常使用的键。

从所有键中，移除最不经常使用的键。不考虑键是否设置了过期时间，只根据访问频率来决定淘汰哪些数据。

从设置了过期时间的键中，随机移除一个键。

从所有键中，随机移除一个键。无论键是否设置了过期时间，都有相同的概率被随机选中并删除。

从设置了过期时间的键中，移除剩余生存时间最短的键。也就是优先删除那些即将过期的键。

以及当内存达到限制时，不进行任何淘汰操作。如果此时有新的数据写入，Redis 会返回错误，阻止新数据的写入。

 

 

 

 

 

 

redis的哨兵机制是怎样的？

会先启动哨兵进程，需要在配置文件中指定要监控的 Redis 主节点信息，包括主节点的 IP 地址、端口号以及监控的名称等。启动多个哨兵进程，它们会自动发现彼此并建立通信连接，形成一个哨兵集群。

然后发现主从节点，哨兵进程启动后，会向配置的主节点发送 INFO 命令，获取主节点的信息，同时也会获取该主节点下所有从节点的信息，从而发现整个主从集群的拓扑结构。

有心跳检测，哨兵会定期向主从节点发送 PING 命令，根据节点的响应情况来判断节点是否正常。默认情况下，每隔 1 秒就会向所有被监控的节点发送 PING 命令。

如果某个节点在一定时间内没有响应 PING 命令，哨兵会将该节点标记为 “主观下线”。这只是单个哨兵的判断，可能存在误判。

当一个哨兵将主节点标记为 “主观下线” 后，它会向其他哨兵发送询问，了解它们对该主节点的状态判断。如果超过一定数量的哨兵都认为该主节点 “主观下线”，那么该主节点就会被标记为 “客观下线”。这表明主节点确实出现了故障。

当主节点被标记为 “客观下线” 后，哨兵集群需要选举出一个领导者哨兵，由它来负责后续的故障转移操作。选举过程基于 Raft 算法，通过投票机制选出一个领导者。

领导者哨兵会从从节点中选择一个合适的节点作为新的主节点。选择的规则通常会考虑从节点的优先级、复制偏移量等因素。

然后向选中的从节点发送 SLAVEOF NO ONE 命令，将其提升为新的主节点。

再向其他从节点发送 SLAVEOF 命令，让它们将新的主节点作为复制源，建立新的复制关系。

通过发布 - 订阅机制通知客户端主节点已经发生变更，客户端可以根据新的主节点信息进行连接。

 

 

说说redis的缓存穿透、缓存击穿、缓存雪崩是怎样的？

缓存穿透是指客户端请求的数据在缓存中不存在，并且在数据库中也不存在，导致请求直接穿透缓存到达数据库，给数据库带来压力。

可以使用布隆过滤器，它能快速判断一个元素是否在集合中。在缓存之前先使用布隆过滤器过滤掉不存在的键，避免无效请求到达数据库。另外，也可以对查询结果为空的情况进行缓存，设置一个较短的过期时间，这样下次相同请求就可以直接从缓存中获取空结果，而不会穿透到数据库。

缓存击穿是指缓存中某个热点数据过期的瞬间，大量并发请求同时访问该数据，由于缓存中没有该数据，这些请求会同时穿透到数据库，导致数据库压力瞬间增大。

、可以采用互斥锁的方式，在缓存数据过期时，只允许一个请求去数据库查询数据并更新缓存，其他请求则等待该请求完成后从缓存中获取数据。另外，也可以考虑延长热点数据的过期时间，或者采用 “永不过期” 的策略，通过定期异步更新数据来保证数据的新鲜度。

缓存雪崩是指在同一时刻，大量的缓存数据同时过期或者 Redis 服务器出现故障，导致大量请求直接涌向数据库，使数据库压力剧增，甚至可能导致数据库崩溃。

对于过期时间集中的问题，可以将缓存数据的过期时间设置为随机值，避免大量数据同时过期。同时，可以采用多级缓存架构，如在应用服务器本地设置一级缓存，再加上 Redis 作为二级缓存，当 Redis 中的数据失效时，先从本地缓存中获取数据，减轻数据库的压力。另外，为了应对 Redis 服务器故障，可以搭建 Redis 集群，实现数据的冗余和高可用性。

有看过redis的底层源码吗？

看过哈希类型键值对的实现， 采用了类似字典的哈希表结构，有哈希表节点，用于存放键值对，其中包含键、值以及指向下一个节点的指针，

有哈希表，一个二维数组，由多个哈希表节点组成，还包含了大小、掩码和当前节点数量等元数据，

有字典，对两个哈希表进行管理，在再哈希期间会交替使用这两个哈希表。

当出现哈希冲突时，运用链地址法来处理哈希冲突，也就是当多个键映射到相同槽位时，会通过链表将这些节点串联起来。为了避免链表过长影响查询效率，Redis 在必要时会进行再哈希操作，以此保证哈希表的负载因子处于合理范围。

同时当哈希表需要扩容或者缩容时，不会一次性完成所有键的再哈希，而是采用渐进式的方式，在每次对字典进行增删改查操作时，顺带迁移少量的键到新的哈希表，在再哈希过程中，新旧两个哈希表会同时存在，查询操作会先在旧表中进行查找，如果找不到再到新表中查找。还会在空闲时执行后台再哈希任务，加快迁移的速度。

 

JUC

讲讲线程池参数如何设置？

线程池有多个参数的设置需要考虑。

**·** ***\*核心线程数\*******\*，\****设置时要考虑任务的性质和预期的并发量。如果任务是 CPU 密集型的，通常将核心线程数设置为等于或略大于 CPU 核心数，以充分利用 CPU 资源，避免过多线程竞争导致上下文切换开销增加。如果任务是 I/O 密集型的，由于线程在等待 I/O 操作完成时会处于空闲状态，此时可以设置核心线程数为 CPU 核心数的数倍，以确保有足够的线程来处理 I/O 任务，提高系统的吞吐量。

**·** ***\*最大线程数\*******\*，\****它应该大于或等于核心线程数。当任务队列已满且所有核心线程都在忙碌时，线程池会创建新的线程来处理任务，直到达到最大线程数。最大线程数的设置要考虑系统的资源限制，包括内存、CPU 处理能力等。如果设置过大，可能会导致系统资源耗尽，影响系统的稳定性；如果设置过小，可能无法充分利用系统资源来处理高并发任务。

**·** ***\*任务队列\*******\*，\****有多种类型的队列可供选择，如无界队列和有界队列。无界队列可以无限容纳任务，但可能会导致内存溢出，适用于任务处理速度较快，不会出现大量任务堆积的情况。有界队列则需要设置一个固定的容量，当队列已满时，新的任务会根据线程池的拒绝策略进行处理。设置队列大小时，要根据任务的产生速度和处理速度来权衡，以避免队列过长导致任务延迟过高，或者队列过小导致任务被拒绝。

**·** ***\*线程存活时间\*******\*，\****多余的线程在空闲一段时间后会被销毁，这个空闲时间就是线程存活时间。设置合理的线程存活时间可以避免资源浪费，同时又能保证在有新任务到来时可以快速响应。如果存活时间设置过短，可能会导致线程频繁创建和销毁，增加系统开销；如果设置过长，可能会导致线程长时间闲置，占用系统资源。

**·** ***\*拒绝策略\*******\*，\****常见的拒绝策略有直接拒绝、丢弃最老的任务、丢弃当前任务和由调用者线程处理等。选择合适的拒绝策略要根据业务需求来决定。例如，对于一些对实时性要求不高的任务，可以选择丢弃最老的任务；对于一些不能丢失的任务，可以选择由调用者线程处理，让调用者自己决定如何处理任务。

 

线程池有哪几种？

***\*固定大小线程池\*******\*，\****线程池中的线程数量固定不变，由创建线程池时指定。它适用于处理具有稳定并发量的任务，能有效控制线程数量，避免线程频繁创建和销毁带来的开销。例如，在一个服务器中处理固定数量的并发请求，就可以使用固定大小线程池。

***\*可缓存线程池\*******\*，\****线程池中的线程数量会根据任务数量动态调整。如果有空闲线程，会优先使用空闲线程处理任务；如果没有空闲线程，会创建新的线程来处理任务。当线程空闲一段时间后，会被销毁。这种线程池适用于处理突发的、并发量变化较大的任务，能灵活地适应任务量的变化。例如，在处理用户的搜索请求时，搜索量可能会突然增加或减少，可缓存线程池就可以很好地应对这种情况。

***\*单例\*******\*线程池\*******\*，\****线程池中只有一个线程，所有任务按照提交顺序依次执行。它保证了任务的顺序执行，适用于需要按顺序处理任务，且不希望有并发执行的场景。比如，在处理一些对数据一致性要求很高的任务时，如银行转账操作，使用单线程线程池可以确保每个转账任务依次执行，避免数据不一致的问题。

***\*定时线程池\*******\*，\****用于定时或周期性执行任务。可以指定任务在特定的延迟后执行，或者按照一定的时间间隔周期性地执行。例如，在一个定时任务系统中，需要每天凌晨执行数据备份任务，就可以使用定时线程池来实现。

***\*分治并行线程池，\****是 Java 7 引入的一种专门用于处理能够被分解成多个子任务，且子任务之间可以并行执行的线程池，它基于分治思想和工作窃取算法来提高并行处理效率。

核心特点在于其工作窃取算法。每个工作线程都有自己的双端队列来存储任务。当一个线程完成了自己队列中的任务后，它会随机选择其他线程的队列，从队尾窃取一个任务来执行。这样可以保证线程资源得到充分利用，避免有的线程忙碌而有的线程闲置的情况，从而提高整体的并行处理性能。

适用于能够进行任务分解和结果合并的场景。除了上述的数组求和，还常用于对大规模数据集合进行操作，如排序、搜索等。在处理树结构数据时，例如遍历树并计算节点属性，也可以将树的不同分支作为子任务，通过分治并行线程池并行处理，以加快处理速度。此外，在一些需要高效利用多核处理器的计算密集型任务中，也能发挥很好的作用，充分利用多核优势，提升计算效率。

 

新的任务被提交到线程池会做什么？

线程池首先会检查自身的状态，判断线程池是否正在运行、是否已关闭或处于其他特殊状态。如果线程池已关闭，那么新任务可能会根据具体的策略被拒绝执行，并返回相应的错误信息。

然后查看当前已创建的核心线程数是否达到了设定的核心线程数上限。如果核心线程尚未满，线程池会创建一个新的核心线程来执行新提交的任务。

如果核心线程已满，线程池会将任务放入任务队列中。任务队列有多种类型，如无界队列、有界队列等。如果任务队列是有界队列，且队列已经满了，但当前线程池的线程数没到最大线程数会临时创建线程来处理任务，若当前线程池的线程数达到了最大线程数，那么会根据线程池的拒绝策略来处理新任务。

如果任务队列已满，线程池会检查当前线程数是否达到了最大线程数限制。如果未达到最大线程数，线程池会创建非核心线程来执行新任务。

无论是核心线程还是非核心线程，在获取到任务后，都会执行任务中的具体逻辑。线程会从任务队列中取出任务，然后调用任务的执行方法来完成任务的处理。

任务执行完成后，线程会进行一些清理工作，如释放任务执行过程中占用的资源等。然后线程会回到线程池中，等待下一个任务的分配。如果线程池中的线程长时间没有任务可执行，超过了一定的空闲时间，非核心线程可能会被销毁，以节省系统资源。不同的线程池实现可能会在具体细节上有所差异，但总体的处理流程大致是相似的。线程池通过这种方式来管理线程和任务，实现任务的高效执行和资源的合理利用，提高系统的性能和稳定性。

任务被放在队列里面，有些线程被释放了，队列的任务怎么被线程消费呢？

·线程池会定期检查是否有空闲线程。即使有部分线程被释放，但只要线程池未被完全销毁且还有核心线程存在，这些核心线程在完成当前任务后会尝试从队列中获取新的任务进行执行。

同时当线程池中的现有线程无法满足任务处理需求，即所有线程都在忙碌且任务队列不为空时，线程池会根据配置的策略来决定是否创建新的线程。

如果线程池允许创建新线程，那么会创建新的线程来从队列中获取任务并执行。新线程创建后会立即投入到任务队列中获取任务进行处理，以尽快处理积压在队列中的任务。

 

线程池怎么保证一个任务不会被多个线程重复消费呢？

Java 线程池在设计上就保证了任务调度的原子性。线程池会依次从任务队列里获取任务，且每次只会有一个线程能成功获取任务。一旦某个线程获取到任务，该任务就会从队列中移除，其他线程也就无法再次获取这个任务。

实现则是利用任务队列所具备的线程安全的特性。当一个线程尝试从队列中取出任务时，队列内部的同步机制会保证同一时间只有一个线程能够进行取出操作。像LinkedBlockingQueue和ArrayBlockingQueue这些常见的队列，都通过锁机制或者无锁算法来保证操作的原子性，从而避免多个线程同时取出同一个任务。

 

看过线程池的源码吗？

有看过核心实现类ThreadPoolExecutor，有几个关键属性，

线程池状态，用于表示线程池当前的运行状态，如运行、关闭、终止等。不同状态决定了线程池对新任务的处理方式。

线程数量，记录线程池里当前线程的数量，包含核心线程和非核心线程。

任务队列，用于存放提交但还未处理的任务。

线程工厂，负责创建新的线程。

拒绝策略，当线程池满且任务队列也满时，决定如何处理新提交的任务。

其中线程池状态和线程数量由一个AtomicInteger变量来控制。这个变量的高几位表示线程池状态，低几位表示线程数量。通过这种方式，利用一个变量就可以原子性地操作线程池状态和线程数量，避免了并发问题。

以及线程池中的非核心线程在空闲一段时间后会被回收。当线程从任务队列中获取任务时，如果在指定的时间内没有获取到任务，线程会自动退出，从而实现线程的回收。

 

线程池提交的方式？

有execute方式，是Executor接口中的方法，ThreadPoolExecutor实现了该接口，可用于向线程池提交任务。接收一个Runnable类型的参数，也就是一个实现了run方法的任务对象，该方法定义了任务要执行的具体操作。

·这种方式提交的任务没有返回值，同时当任务执行过程中出现异常时，如果没有在任务内部进行捕获处理，那么这个异常会导致执行该任务的线程终止，但不会影响线程池中的其他线程继续执行其他任务。

以及submit方式，ExecutorService接口中的方法，ThreadPoolExecutor也实现了该接口。submit方法有多种重载形式，可以接收Runnable或Callable类型的参数。

·当提交Callable任务时，该方法会返回一个Future对象，通过这个Future对象可以在任务执行完成后获取任务的执行结果。如果提交的是Runnable任务，也会返回一个Future对象，不过调用其get方法时返回的是null，因为Runnable任务没有返回值。

通过Future对象的get方法获取结果时，如果任务执行过程中抛出了异常，get方法会将这个异常重新抛出，需要在调用get方法的地方进行捕获和处理。

 

 

任务被放在队列里面，有些线程被释放了，队列的任务怎么被线程消费呢？

线程池会定期检查是否有空闲线程。即使有部分线程被释放，但只要线程池未被完全销毁且还有核心线程存在，这些核心线程在完成当前任务后会尝试从队列中获取新的任务进行执行。

同时当线程池中的现有线程无法满足任务处理需求，即所有线程都在忙碌且任务队列不为空时，线程池会根据配置的策略来决定是否创建新的线程。

如果线程池允许创建新线程，那么会创建新的线程来从队列中获取任务并执行。新线程创建后会立即投入到任务队列中获取任务进行处理，以尽快处理积压在队列中的任务。

 

 

 

怎么接收线程池的返回值？

可以使用submit方法提交Callable任务，submit方法接收一个Callable类型的参数，并返回一个Future对象，借助这个Future对象就能获取任务的返回值。

也可以使用ExecutorService接口提供的invokeAll和invokeAny方法，其中invokeAll方法接收一个Callable任务列表，返回一个包含Future对象的列表，每个Future对象对应一个任务的执行结果。该方法会等待所有任务完成后才返回。

invokeAny方法则是接收一个Callable任务列表，返回其中一个已经完成的任务的结果。一旦有一个任务完成，该方法就会立即返回，其他未完成的任务可能会被取消。

 

如何查看线程池的状态？

可以利用ThreadPoolExecutor类的方法getPoolSize，这个方法会返回线程池当前的线程数量，它包含正在执行任务的线程以及空闲的线程。

getActiveCount，返回正在执行任务的线程数量。

getQueue().size()，返回任务队列中等待执行的任务数量。

isShutdown，用于判断线程池是否已经调用了shutdown方法。调用shutdown方法后，线程池将不再接受新的任务，但会继续执行已经提交的任务。

isTerminated，判断线程池是否已经完全终止。当所有任务都执行完毕，并且所有线程都已经销毁时，线程池才会被认为是终止状态。

getLargestPoolSize，返回线程池在运行过程中达到的最大线程数。

除了使用ThreadPoolExecutor类的方法，还可以结合日志来查看线程池的状态。

比如在代码中添加日志记录，记录线程池的关键状态变化，例如线程池的启动、关闭、任务提交和完成等。这样可以帮助跟踪线程池的运行过程，及时发现问题。

 

提交到线程池的任务执行异常了，如何获取这个异常？

当使用execute方法提交任务时，为了获取异常信息，可采用自定义ThreadFactory，能为每个线程设置UncaughtExceptionHandler。当线程因未捕获的异常而终止时，UncaughtExceptionHandler就会被调用，进而获取异常信息。

或设置默认的UncaughtExceptionHandler，可以为线程池中的所有线程设置默认的UncaughtExceptionHandler，这样当线程出现未捕获的异常时，就能捕获到异常信息。

使用submit方法提交任务时，该方法会返回一个Future对象。可以调用Future对象的get方法来获取任务的执行结果。如果任务执行过程中抛出异常，get方法会将该异常封装在ExecutionException中抛出。通过捕获ExecutionException并调用其getCause方法，就能获取到实际的异常信息。

 

 

说说hashmap的底层原理？

· JDK 1.7 及之前，HashMap的底层数据结构是数组加链表，JDK 1.8 及之后是数组加链表/红黑树。

· 数组用于存储键值对的桶，每个桶可以存储一个键值对或一个链表

· 当链表长度超过一定阈值时，链表会转化为红黑树，以提高查找效率，这个阈值在jdk1.8中默认是8。

· 以及当不同的键通过哈希函数计算得到相同的桶索引时，就会发生哈希冲突。

· JDK 1.7 及之前采用头插法将新的键值对插入到链表头部。

· JDK 1.8 及之后采用尾插法插入，并在链表长度超过阈值时转换为红黑树。当红黑树节点数量小于一定阈值时，又会退化为链表。

 

hashmap的扩容机制是怎样的？

· 当HashMap中的键值对数量超过了负载因子与当前数组容量的乘积时，就会触发扩容。默认情况下，负载因子为 0.75，即当size > capacity * 0.75时，进行扩容。

· 先创建一个新的数组，其容量是原来数组容量的两倍。

· 再将原数组中的所有键值对重新分配到新的数组中。这是通过重新计算每个键的哈希值，并根据新的数组容量来确定其在新数组中的位置实现的。

· 在将键值对重新分配到新数组的过程中，需要重新计算键的哈希值和在新数组中的索引位置。由于数组容量发生了变化，原来的哈希值与数组长度的取模结果也会改变。

· 重新哈希并非简单地重新计算哈希码和取模，JDK 1.8 中对重新哈希的过程进行了优化。利用了扩容后数组长度是原来的 2 倍这一特性，通过位运算来高效地确定键值对在新数组中的位置，减少了计算量。

通过扩容机制，HashMap 能够在元素数量增加时，保持较低的哈希冲突概率，从而维持较好的性能。但扩容操作也会带来一定的性能开销，因为需要重新分配内存空间和重新哈希所有的键值对，所以在使用 HashMap 时，若能提前预估数据量大小，合理设置初始容量，可减少扩容次数，提高性能。

 

说说Concurruenthashmap的底层原理？

· JDK 1.8 及之后ConcurrentHashMap的底层数据结构与HashMap类似，也是数组加链表 / 红黑树。它由多个Node数组组成，每个Node数组称为一个桶。

· 当桶中的元素以链表形式存储时，链表长度超过一定阈值时会转换为红黑树，以提高查找效率。

· 在 JDK 1.7 中，ConcurrentHashMap采用了分段锁的机制来实现线程安全。它将整个哈希表分为多个段，每个段都是一个独立的哈希表，有自己的锁。

· 不同段之间的操作可以并发执行，只有在访问同一个段时才需要获取相应段的锁。这样可以提高并发度，允许多个线程同时访问不同段的数据。

· JDK 1.8 对ConcurrentHashMap的实现进行了优化，不再使用分段锁，而是采用CAS和synchronized关键字相结合的方式来保证线程安全。

· 在插入和更新操作时，首先使用CAS尝试直接在数组中插入或更新元素，如果CAS操作失败，说明有其他线程正在同时修改该位置的元素，此时再使用synchronized关键字对该桶进行加锁，进行后续的插入或更新操作。

· 对于读取操作，由于Node节点中的数据通过volatile关键字修饰，保证了数据的可见性，所以不需要加锁就能获取到最新的数据。

· ConcurrentHashMap的扩容机制与HashMap类似，但在多线程环境下更为复杂。当元素数量超过负载因子与当前数组容量的乘积时，会触发扩容。

· 扩容过程中，会将原数组中的元素迁移到新的更大的数组中。在多线程环境下，多个线程可以同时参与扩容操作，每个线程负责一部分桶的迁移工作。通过transfer方法来实现元素的迁移，该方法会对每个桶进行处理，将其中的元素重新计算哈希值并放入新数组的相应位置。

 

讲一下乐观锁是什么，怎么实现？

乐观锁是一种用于处理并发访问的机制，它基于一种乐观的假设，即认为在大多数情况下，并发访问不会导致数据冲突。

乐观锁假设在数据进行更新操作时，不会发生并发冲突。当需要更新数据时，先检查在读取数据后到更新数据前这段时间内，数据是否被其他线程修改过。如果没有被修改过，则执行更新操作；如果被修改过，则根据具体的策略来处理，如重新读取数据并再次尝试更新，或者放弃更新并提示用户。

常见实现方式有版本号机制，在数据库表中添加一个版本号字段。当数据被读取时，同时获取其版本号。在更新数据时，将当前数据的版本号与数据库中存储的版本号进行比较。如果两者相等，说明在读取数据后没有其他线程对该数据进行修改，允许执行更新操作，并将版本号加 1；如果不相等，说明数据已被其他线程修改，更新操作失败。

以及时间戳机制，与版本号机制类似，使用时间戳来记录数据的最后修改时间。在读取数据时记录其时间戳，更新数据时比较当前时间戳与数据库中存储的时间戳。如果当前时间戳大于数据库中的时间戳，说明数据在读取后没有被修改过，允许更新；否则，更新失败。不过时间戳机制可能存在精度问题，而且在分布式系统中，不同节点的时间同步也可能带来问题。

 

 

cas是什么？

CAS是一种用于实现多线程同步的原子操作。在并发编程中，CAS 操作是一种无锁算法，常用于解决多线程环境下的数据竞争问题，避免使用传统的锁机制带来的性能开销。

CAS 操作包含三个操作数：内存位置V、预期原值A和新值B。当执行 CAS 操作时，它会先比较内存位置 V 中的值是否等于预期原值 A，如果相等，则将内存位置 V 中的值更新为新值 B；如果不相等，则不进行更新操作。整个比较并交换的过程是原子性的，由硬件层面保证，在执行过程中不会被其他线程中断。

 

说一下线程池的创建和调用？

创建需要先根据任务特点选择合适的线程池类型。例如，固定大小线程池适用于已知并发任务数量且相对稳定的场景，它创建固定数量的线程，线程会一直存在并重复利用；可缓存线程池适合处理大量短时间任务，它会根据任务数量动态创建和回收线程，线程空闲一段时间后会被销毁；定时线程池用于定时或周期性执行任务；单例线程池则是只有一个线程的线程池，保证任务按顺序执行。

· 再设置核心参数，包括核心线程数，即线程池中保持活动的最小线程数量；最大线程数，规定了线程池最多能创建的线程数；还有阻塞队列，用于存放暂时无法执行的任务，常见的有有界队列和无界队列，队列的选择会影响线程池的性能和资源占用；此外，还可以设置线程的存活时间，当线程数超过核心线程数时，多余的线程在空闲多长时间后会被销毁。

调用则是先将任务提交给线程池，线程池会按照一定的策略来执行提交的任务。当有任务提交时，线程池首先会检查核心线程是否都在执行任务，如果有空闲的核心线程，则将任务分配给它执行；如果核心线程都在忙碌，且阻塞队列未满，则将任务放入队列中等待；如果核心线程都在忙碌且阻塞队列已满，此时会根据最大线程数来判断是否需要创建新的线程来执行任务；如果线程数已经达到最大线程数，那么就会根据拒绝策略来处理新提交的任务，常见的拒绝策略有直接拒绝、丢弃最老的任务、由提交任务的线程直接执行任务等。

最后，当不再需要使用线程池时，应该关闭线程池以释放资源。可以调用shutdown方法来平滑地关闭线程池，它会等待所有正在执行的任务完成后再关闭线程池；如果希望立即停止所有任务并关闭线程池，则可以使用shutdownNow方法，该方法会尝试中断正在执行的任务，并返回未执行的任务列表。

说说completablefuture？

· 使用completableforFuture可以在后台线程中异步执行任务，而不会阻塞主线程。这样可以提高程序的响应性和性能，特别是在处理耗时操作时，如网络请求、文件读取或复杂的计算。

· 有丰富的方法来组合和编排多个异步任务。可以将多个CompletableFuture对象链接在一起，以便在一个任务完成后自动触发另一个任务，或者将多个任务并行执行并在它们都完成后进行汇总结果。

· 提供了方便的方式来处理异步任务的结果和异常。可以使用回调方法来在任务完成时获取结果，并对结果进行进一步的处理。同时，也可以优雅地处理任务执行过程中抛出的异常，而不会导致程序崩溃。

· 支持非阻塞的编程风格，使得代码更易于阅读和维护。可以使用类似于链式调用的方式来编 写异步代码，避免了传统异步编程中常见的回调地狱问题。

· 

说说volatile关键字？

· Volatile关键字可以保持可见性，在 Java 内存模型中，每个线程都有自己的工作内存，变量的值会被拷贝到工作内存中进行操作，操作完成后再写回主内存。当一个变量被声明为volatile时，它会保证对该变量的写操作会立即刷新到主内存中，而读操作会直接从主内存中读取最新的值。

可以禁止指令重排序，为了提高程序的执行效率，编译器和处理器可能会对指令进行重排序。但在某些情况下，指令重排序可能会导致程序出现错误。volatile关键字可以禁止指令重排序，保证代码的执行顺序与编写顺序一致。

但不保证原子性，因为原子性是指一个操作是不可分割的，要么全部执行，要么全部不执行。volatile关键字并不能保证对变量的操作是原子的。

如何防止ABA?

· 可以使用版本号，给要更新的变量添加一个版本号，每次变量更新时，不仅要比较变量的值，还要比较版本号。只有当变量的值和版本号都与预期相符时，才执行更新操作。这样可以确保在变量值从 A 变为 B 再变回 A 的过程中，版本号会发生变化，从而避免 CAS 操作误判。

· 也可以使用标记，为变量添加一个标记位，用于表示变量是否被修改过。这个标记位可以是一个布尔值，当变量被修改时，标记位被设置为 true；在进行 CAS 操作时，同时检查变量的值和标记位。如果标记位发生了变化，即使变量的值看起来没有变化，也说明变量在中间被修改过，CAS 操作不会执行。

 

线程安全是什么？

线程安全是指在多线程环境下，一个程序或代码片段能够正确地执行，并且不会因为多个线程同时访问和修改共享资源而导致数据不一致、程序崩溃或出现其他错误的特性。

当一段代码是线程安全的，意味着无论有多少个线程同时访问它，都能保证其行为符合预期，不会出现数据竞争***\*，\****多个线程同时访问和修改同一个共享数据，导致数据的最终结果依赖于线程执行的顺序，产生不可预测的结果。

也不会出现资源冲突，多个线程同时访问和使用同一个资源，如文件、网络连接等，可能导致资源被损坏或无法正常使用。

也不会出现状态不一致，由于多线程并发执行，可能导致对象或系统的状态处于不一致的状态，使程序出现错误或异常。

 

Java中如何保证线程安全？

· 可以使用同步代码或同步方法，通过synchronized关键字来实现，它可以确保在同一时刻只有一个线程能够访问被同步的代码块或方法，从而避免数据冲突和不一致性。

· 也可以使用juc包下的Lock接口及其实现类提供了更灵活的锁机制。可以通过显式地获取和释放锁来控制对共享资源的访问，相比于synchronized关键字，Lock锁提供了更多的功能，如可重入锁、公平锁等。

· 还可以使用线程安全的类和容器，如ConcurrentHashMap、CopyOnWriteArrayList等。这些类和容器内部已经进行了线程安全的设计和实现，可以在多线程环境中安全地使用。

· 以及使用juc包下的原提供了原子操作的原子类，这些原子类可以在多线程环境中对单个变量进行原子性的操作，避免了使用锁带来的性能开销。

· 以及创建不可变对象，即对象一旦创建就不能被修改。不可变对象在多线程环境中是线程安全的，因为它们的状态不会被改变，从而避免了数据竞争和不一致性问题。

· 还有使用ThreadLocal类为每个线程提供独立的变量副本，每个线程只能访问自己的副本，从而避免了线程之间的共享数据冲突。

 

知道哪些锁?

· synchronized锁是Java 中最基本的同步机制，可修饰实例方法、静态方法和代码块。当一个线程访问被 synchronized 修饰的方法或代码块时，会自动获取锁，其他线程必须等待该线程释放锁后才能进入。

· 可重入锁，支持可重入性，即同一个线程可以多次获取同一把锁而不会出现死锁。与synchronized相比，它提供了更灵活的锁机制，如可中断锁、公平锁等。

· 可重入读写锁，将读写操作分离，允许多个线程同时进行读操作，但在写操作时会独占锁。这样可以提高并发性能，适用于读多写少的场景。

· 邮戳锁，是 Java 8 引入的一种新的锁机制，它提供了乐观读锁、悲观读锁和写锁三种模式。乐观读锁在读取数据时不会加锁，只有在写入数据时才会检查数据是否被修改，从而提高了并发性能。

· 公平锁和非公平锁，公平锁是指多个线程按照申请锁的顺序来获取锁，而非公平锁则不保证线程获取锁的顺序，可能会导致某些线程长时间得不到锁。

自旋锁，是一种忙等待的锁机制，当一个线程尝试获取锁时，如果锁已经被其他线程持有，该线程会不断地循环检查锁的状态，而不是进入阻塞状态。自旋锁适用于锁的持有时间较短的场景。

 

TheadLocal的原理是什么？

每个Thread对象内部都有一个ThreadLocalMap类型的成员变量。这个变量就像一个容器，专门用来存放该线程所对应的所有ThreadLocal变量及其对应的值。

以及有ThreadLocalMap对象，ThreadLocal的一个静态内部类，类似于HashMap，但实现细节有差异。采用数组来存储键值对，其中键是ThreadLocal对象，值是该ThreadLocal为当前线程存储的变量副本。这里的键是弱引用类型，这样做有助于在ThreadLocal对象不再被使用时能被垃圾回收，避免内存泄漏。

当线程调用ThreadLocal的set方法来存储一个值时，会先找到当前线程，然后查看该线程内部的ThreadLocalMap是否已经存在。

如果ThreadLocalMap已经存在，就把当前ThreadLocal对象当作键，要存储的值当作值，一起存到ThreadLocalMap 里。

如果ThreadLocalMap还不存在，就会创建一个新的ThreadLocalMap，并把当前ThreadLocal对象和要存储的值作为第一对键值对存进去，同时将这个新创建的ThreadLocalMap关联到当前线程。

当线程调用ThreadLocal的get方法来获取值时，同样先找到当前线程，接着查看其内部的ThreadLocalMap。

如果ThreadLocalMap存在，就用当前ThreadLocal对象作为键去ThreadLocalMap里查找对应的值。

如果找到了对应的键值对，就返回存储的值；要是ThreadLocalMap不存在或者没找到对应的键值对，就会返回初始值。

当线程调用ThreadLocal的remove方法时，会从当前线程的ThreadLocalMap中把当前的ThreadLocal对象对应的键值对移除，释放相关的内存空间。

 

以及ThreadLocalMap中的键使用弱引用，主要是为了避免内存泄漏。当外部程序对ThreadLocal对象的强引用被释放后，由于ThreadLocalMap里的键是弱引用，在垃圾回收时，这个ThreadLocal对象就会被回收。后续在对ThreadLocalMap进行操作时，会检查并清理那些键为null的键值对，防止无用数据一直占用内存。

 

说说synchronized底层的机制？

synchronized底层机制主要基于Java对象头和监视器实现，Java每个对象都有一个对象头，对象头中包含了一些与对象相关的元数据信息。

每个Java对象都可以关联一个监视器，当一个线程想要访问被synchronized修饰的代码块或方法时，需要先获取该对象的监视器。

当一个线程进入synchronized代码块或方法时，会尝试获取该对象的监视器。

如果监视器没有被其他线程持有，当前线程会成功获取监视器，并将其计数器加1，表示该线程已经持有了锁。

如果当前线程已经持有了该对象的监视器，再次进入synchronized代码块或方法时，会将 监视器的计数器再次加 1，即synchronized的可重入性。

当线程执行完synchronized代码块或方法后，会将监视器的计数器减 1。当计数器减为 0 时，表示该线程已经释放了锁，其他线程可以竞争获取该对象的监视器。

synchronized关键字在编译后会在同步块的前后分别插入monitorenter和monitorexit字节码指令。monitorenter指令会尝试获取对象的监视器，monitorexit指令会释放对象的监视器。

JVM 在执行这些字节码指令时，会根据对象头中的锁状态信息来决定是使用偏向锁、轻量级锁还是重量级锁。

 

 

 

 

 

Hashmap为什么要用红黑树？

因为链表在极端情况下存在性能问题，在 JDK 1.8 之前，HashMap 内部是数组加链表的结构。当大量元素通过哈希函数计算后映射到数组的同一个位置时，这些元素会在该位置形成一个链表。而链表的查找操作需要从头节点开始逐个遍历，时间复杂度是O（n），其中n是链表的长度。如果链表过长，查找效率会变得非常低。

同样，链表的插入和删除操作在需要查找特定节点时，也会受到遍历链表的时间开销影响，尤其是在链表较长时，性能会显著下降。

而红黑树是一种自平衡的二叉搜索树，它通过对节点进行着色以及特定的插入和删除操作来保证树的高度相对平衡。这意味着红黑树的左右子树的高度差不会过大，避免了普通二叉搜索树在极端情况下退化为链表的问题。

且查找、插入和删除操作效率高，由于红黑树的自平衡特性，其查找、插入和删除操作的时间复杂度都是O（logn），其中n是树中节点的数量。相比于链表的O（n）复杂度，红黑树在处理大量数据时性能优势明显。

而且在实际应用中，哈希冲突的分布可能是不均匀的。红黑树的引入使得 HashMap 能够更好地应对这种不均匀的哈希冲突，即使在某些位置出现大量冲突，也能保持较好的性能。

 

 

MQ

消息队列的优点缺点有哪些？

优点：

解耦。比如，用户下单后，订单系统需要通知库存系统，假如库存系统无法访问，则订单减库存将失败，从而导致订单操作失败。订单系统与库存系统耦合，这个时候如果使用消息队列，可以返回给用户成功，先把消息持久化，等库存系统恢复后，就可以正常消费减去库存了。

异步。将消息写入消息队列，非必要的业务逻辑以异步的方式运行，不影响主流程业务。

削峰。消费端慢慢的按照数据库能处理的并发量，从消息队列中慢慢拉取消息。在生产中，这个短暂的高峰期积压是允许的。比如秒杀活动，一般会因为流量过大，从而导致流量暴增，应用挂掉。这个时候加上消息队列，服务器接收到用户的请求后，首先写入消息队列，如果消息队列长度超过最大数量，则直接抛弃用户请求或跳转到错误页面。

缺点：

系统可用性降低。引入消息队列之后，如果消息队列挂了，可能会影响到业务系统的可用性。

系统复杂性增加。加入了消息队列，要多考虑很多方面的问题，比如一致性问题、如何保证消息不被重复消费、如何保证消息可靠性传输等。

 

 

 

 

 

 

各个消息队列的对比？

万级的RabbitMQ的吞吐量要比十万级甚至是百万级的RocketMQ和Kafka低一个数量级。

都可以实现高可用。 RabbitMQ 是基于主从架构实现高可用性。RocketMQ 基于分布式架构。 kafka 也是分布式的，一个数据多个副本，少数机器宕机，不会丢失数据，不会导致不可用。RabbitMQ基于erlang 开发，所以并发能力很强，性能极其好，延时很低，达到微秒级。其他两个都是ms级。

除了Kafka，其他两个功能都较为完备，Kafka主要支持简单的MQ功能。

RabbitMQ消息丢失的可能性非常低，RocketMQ和Kafka理论上不会丢失。

 

 

如何保证消息顺序性？

消息顺序性分为全局顺序性和分区顺序性，全局顺序要求所有消息严格按发送顺序处理，rocketmq通过单队列 + 单生产者 + 单消费者实现，创建只有1个队列的Topic，生产者和消费者均使用单实例。

而分区顺序性指同一组消息如同一用户的操作按顺序处理，不同组之间无需保证顺序。生产者建立路由规则，同一规则的消息发送到固定队列，每个队列由一个消费者线程处理，确保顺序。

 

 

如何保证rocketmq的高可用？

Rocketmq有nameserver和broker，nameserver 因为是无状态，且不相互通信的，所以只要集群部署就可以保证高可用，broker的高可用是体现在读和写的高可用，通过集群和主从实现。

Broker 可以配置两种角色，主和从，主角色的Broker支持读和写，从角色的 Broker 只支持读，主会向从同步消息。

也就是说生产者只能向主角色的Broker写入消息，消费者可以从主和从角色的Broker读取消息。

 

消费者的配置文件中，并不需要设置是通过主角色读还是通过从角色读，当主角色不可用或者繁忙的时候，消费者的读请求会被自动切换到从角色。有了自动切换消费者这种机制，当一个主角色的机器出现故障后，消费者仍然可以通过从角色读取消息，不影响消费者读取消息，这就实现了读的高可用。

写的高可用性则是在创建主题的时候，把主题的多个Message Queue创建在多个Broker组上，这样当一个Broker组的主角色不可用后，其他组主角色仍然可用， 生产者仍然可以发送消息。

 

如何避免消息重复消费？

可以为每条消息分配全局唯一ID，并创建一张mysql表记录消息的全局唯一id或在redis中缓存全局唯一id，消费前检查该id是否已在mysql或redis中有记录，若有记录则不再处理该消息。

 

介绍一下rocketmq的死信队列和延迟队列？

Rocketmq的死信队列用于存储无法被正常消费且重试次数耗尽的消息，避免消息丢失并支持后续排查与处理。

一般是由于消费者消费消息时抛出异常，且消息的重试次数达到预设上限时消息进入死信队列，或通过消费者主动将消息标记为死信的方式让消息进入死信队列。

可以通过创建监听死信队列的消费者处理死信消息，或通过rocketmq的控制台删除死信消息。

延迟队列则用于实现消息发送后延迟指定时间再被消费的场景，RocketMQ通过延迟级别机制原生支持延迟队列。

RocketMQ而是预设了多个延迟级别，对应不同的延迟时长，延迟消息发送时，会先被存储在一个内部延迟主题中，Broker 根据延迟级别对应的时间，到期后将消息转发到目标主题，此时消费者可正常消费。

 

如何实现rocketmq的流量削峰、异步解耦？

流量削峰是接口流量过高时生产消息，将部分请求的传参传到消息队列去，当流量降下来后再用这些请求传参去调用接口，异步解耦则是将原先完整的接口工作拆出一部分交给消息队列去处理，一般是不需要返回结果的工作交给消息队列去处理。

 

 

 

 

 

ElasticSearch

为什么用es？

因为它基于倒排索引结构，能提供高效、精准的全文搜索，支持复杂的查询语法和多种搜索策略，可快速从海量数据中检索出相关信息。

具备良好的分布式架构，能轻松扩展到多个节点，以处理大规模数据和高并发的搜索请求。随着业务增长，数据量和用户访问量不断增加，ES 可以通过添加节点来提高系统的性能和容量，保证服务的稳定性和响应速度。

支持多种数据格式和类型，包括结构化数据、半结构化数据和非结构化数据，还允许用户根据具体需求自定义索引结构和映射关系，能适应不同的业务场景和数据特点。

提供了丰富的数据分析功能，如聚合操作，可对数据进行分组、统计和计算，还能与 Kibana 等可视化工具集成，方便用户直观地展示和分析数据，帮助用户更好地理解数据和发现问题。

es为什么高效（快）？

采用了倒排索引结构，快速定位数据。采用分布式架构，可以将数据分布在多个节点上，通过增加节点来实现水平扩展。这种分布式架构能够处理大规模的数据，并且随着数据量的增加，性能不会受到明显的影响。

在分布式环境中，es会自动进行负载均衡，将查询请求均匀地分配到各个节点上，避免单个节点出现过载的情况。这样可以充分利用集群中各个节点的资源，提高整体的查询处理能力和响应速度。

同时es使用内存缓存来存储经常访问的数据和查询结果。当一个查询被执行时，它会首先检查缓存中是否有对应的结果，如果有，则直接从缓存中返回，避免了再次执行查询操作，从而大大提高了查询效率。

还会对索引数据进行缓存，将经常访问的索引块存储在内存中，这样可以减少磁盘 I/O 操作，提高索引的读取速度，进而加快查询的执行。

以及支持对数据、索引数据和文档进行压缩。压缩后的数据可以大大减少存储空间的占用，同时也降低了磁盘I/O的压力，提高了数据的读写速度。

且es在执行查询之前，会解析查询语句的语法，将其转换为内部的查询执行计划，并根据索引的结构和数据分布情况，选择最优的查询执行策略。

讲讲es架构（讲讲es集群架构）？

有主节点，负责管理集群的元数据，如索引的创建、删除，节点的加入、离开等操作。主节点通过选举产生，一个集群中只有一个主节点处于活跃状态，其他主节点候选则处于待命状态。

有数据节点，用于存储实际的数据，并执行数据的索引和搜索操作。数据节点可以根据集群的规模和数据量进行扩展，以提高集群的存储和处理能力。

有协调节点，负责接收客户端的请求，并将请求分发到相应的数据节点上执行。协调节点还会对数据节点返回的结果进行合并和排序，然后将最终结果返回给客户端。

有索引，具有相同结构和映射关系的文档集合，类似于关系型数据库中的表。在ES集群中，索引可以分布在多个节点上，以实现数据的分布式存储和并行处理。

有分片，索引可以被划分为多个分片，每个分片是一个独立的Lucene索引。分片可以分布在不同的节点上，从而实现数据的分布式存储和负载均衡。ES 集群会自动管理分片的分布和复制，确保数据的高可用性和容错性。

当客户端向 ES 集群写入数据时，数据首先会被发送到协调节点。协调节点根据文档的路由规则，将数据分发到对应的主分片所在的数据节点上。

主分片接收数据后，会将数据写入本地的 Lucene 索引，并将数据复制到对应的副本分片上。副本分片写入成功后，主分片会向协调节点返回写入成功的响应，协调节点再将响应返回给客户端。

需要读取数据时，客户端发送读取请求到协调节点，协调节点根据请求的内容，将请求分发到包含相关数据的分片所在的数据节点上。

数据节点执行查询操作，并将结果返回给协调节点。协调节点对各个数据节点返回的结果进行合并和排序，然后将最终结果返回给客户端。

 

 

 

讲讲es的倒排索引？

传统的索引结构是 “文档 -> 词” 的映射关系，即根据文档找到其中包含的词。而倒排索引则是 “词 -> 文档” 的映射，它记录了每个词在哪些文档中出现过，以及在文档中的位置信息。

当文档被添加到 ES 中时，首先会对文档内容进行分词处理，将文本拆分成一个个独立的词。

对于每个词，ES 会记录它出现的文档列表，以及在每个文档中的位置信息。

并将构建好的倒排索引存储在磁盘上，以便后续的查询操作。为了提高查询效率，ES 还会对索引进行压缩和优化。

倒排索引能够快速定位包含特定词的文档，无需遍历所有文档。当用户输入一个查询词时，ES 可以直接通过倒排索引找到包含该词的文档列表，大大提高了查询速度。

支持多种复杂的查询操作，如布尔查询、短语查询、模糊查询等。通过对多个倒排表进行逻辑组合，可以实现精准的搜索匹配。

在处理大规模数据时，倒排索引的优势更加明显。由于它只需要关注包含查询词的文档，而不是整个文档集合，因此可以在短时间内处理大量的数据。

 

 

 

 

 

JVM

说说JVM内存模型?

有程序计数器，一块较小的内存空间，可以看作是当前线程所执行的字节码的行号指示器。在 JVM 的概念模型里，字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成，是线程私有的。

有虚拟机栈，也是线程私有的，它的生命周期与线程相同。虚拟机栈描述的是 Java 方法执行的内存模型，每个方法在执行的同时都会创建一个栈帧用于存储局部变量表、操作数栈、动态链接、方法出口等信息。每一个方法从调用直至执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。

有本地方法栈，与虚拟机栈所发挥的作用是非常相似的，它们之间的区别不过是虚拟机栈为虚拟机执行 Java 方法服务，而本地方法栈则为虚拟机使用到的本地方法服务。

有堆，被所有线程共享的一块内存区域，在虚拟机启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。这也是 Java 垃圾回收器管理的主要区域，因此也被称为 “GC 堆”。

有方法区，与 Java 堆一样，是各个线程共享的内存区域，它用于存储已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。

gc是什么? gc是怎样的执行过程？

GC是垃圾回收，GC 的主要作用就是自动检测并回收不再使用的对象所占用的内存，让程序员无需手动管理内存的分配和释放，从而降低了内存管理的复杂度和出错的可能性。

执行过程是先确定哪些对象是存活的，哪些是可回收的，常用可达性分析算法，从gc roots对象开始，递归遍历所有引用的对象，被引用的对象标记为存活，再通过垃圾回收器回收垃圾对象占用的内存空间，常用算法有标记清除、标记整理、复制算法等。最后进行内存压缩，整理内存空间，消除碎片，提高内存分配效率。

 

 

什么是gc roots、标记清除、标记整理、复制算法？

Gc roots包括静态变量、栈帧中的本地变量、JNI 引用等。

标记清除算法是直接删除标记为垃圾的对象，可能产生内存碎片。

标记整理算法是先标记垃圾，再将存活对象移动到连续内存空间，避免碎片。

复制算法是将内存分为两半，存活对象复制到另一半，清空原区域。

 

说说常见的垃圾回收器?

·串行垃圾回收器，单线程，在进行垃圾回收时，会暂停所有的用户线程。

·并行垃圾回收器，多线程，关注系统的吞吐量，在进行垃圾回收时也会暂停用户线程，但通过多线程并行回收可以提高回收效率。

·CMS垃圾回收器，以获取最短回收停顿时间为目标，在进行垃圾回收时，尽量减少用户线程的停顿时间。

·G1垃圾回收器，一种面向服务器的垃圾回收器，能够同时兼顾吞吐量和低延迟。它将堆内存划分为多个大小相等的区域，根据每个区域中垃圾的数量和回收价值进行优先回收。

Zgc垃圾回收器， 进行垃圾回收时暂停所有的用户线程时间极短，不超过10ms，内存不分代，视为一个整体，使用着色指针和读屏障进行垃圾回收。

 

什么是jvm的分代？

将内存分为多个代，针对不同代的对象特性采用不同的GC策略。大部分垃圾回收器都会采用内存分代方案。

有新生代，分为eden区和两个survivor区，新对象优先分配在eden区，eden区满时触发gc，存活对象移至survivor，新生代gc频繁但gc速度快。

有老年代，存放新生代中多次gc后仍存活的对象，默认15次，空间不足时触发gc，gc频率较低但速度慢。

串行、并行、cms、g1垃圾回收器对新生代都采用复制算法清除，对于老年代除了cms是采用标记清除算法，串行、并行、g1垃圾回收器都是采用标记整理算法。

以及jdk8前的永久代和jdk8后的元空间，存储类元数据、静态变量等，空间不足时触发gc。

串行、并行、cms垃圾回收器对永久代采用标记整理算法，g1垃圾回收器只对元空间采用清除算法，串行、并行、cms、g1垃圾回收器对元空间均采用并发标记-清除算法。

 

 

你知道哪些Jvm调优策略？

合理设置堆大小，堆大小设置过小会导致频繁的垃圾回收，甚至引发内存溢出错误，设置过大则可能会增加垃圾回收的停顿时间。可以分别设置堆的初始大小和最大大小，通常将这两个值设置为相同，避免堆在运行过程中频繁扩容和缩容。

调整新生代和老年代比例，对于创建对象频繁的应用程序，可以适当增大新生代的比例，减少对象在新生代和老年代之间的移动，从而减少垃圾回收的次数。

设置永久代或元空间大小，如果应用程序加载的类较多，可能需要适当增大元空间的大小。

以及根据应用场景选择合适的垃圾回收器和调整垃圾回收器相关参数。

还可以分析垃圾回收日志，了解垃圾回收的频率、停顿时间、回收对象的大小等信息，从而判断垃圾回收器的性能和内存使用情况。根据分析结果，调整堆大小、垃圾回收器等参数。

 

 

类加载机制是怎样的?

类加载主要包括加载、连接和初始化三个阶段。先是加载，类加载器根据类的全限定名查找对应的字节码文件，将找到的字节码文件读取到内存中，根据字节码内容在内存中创建一个java.lang.Class对象，该对象是类在JVM中的唯一表示。

再是连接，先验证确保加载的字节码文件符合 JVM 的规范，不会对 JVM 造成安全威胁。验证内容包括文件格式验证、元数据验证、字节码验证和符号引用验证等。

然后为类的静态变量分配内存，并设置默认初始值。最后解析，将类中的符号引用转换为直接引用。

最后初始化，对执行类的静态代码块和静态变量进行显式赋值操作。静态代码块和静态变量的初始化顺序按照它们在类中定义的顺序执行。

 

双亲委派机制是怎样的？

当一个类加载器接收到类加载请求时，它会先检查该类是否已经被加载过。如果未被加载，它会将请求委托给父类加载器。比如，应用程序类加载器收到请求后，会先将请求委托给扩展类加载器，扩展类加载器再将请求委托给启动类加载器。

启动类加载器会首先尝试加载该类，如果它能找到并加载该类，则完成类加载过程。如果启动类加载器无法加载，它会将请求回传给扩展类加载器，让扩展类加载器尝试加载。

若扩展类加载器也无法加载，再回传给应用程序类加载器进行加载。如果应用程序类加载器也无法加载，则会抛出异常。

通过双亲委派机制，所有的类加载请求最终都会先由启动类加载器尝试加载，这可以防止用户自定义的类覆盖核心的 Java 类，具有较高的安全性。

同时无论一个类在程序的何处被加载，因为类加载器在加载类之前会先检查该类是否已经被加载过，只有未被加载的类才会被加载，只要它的全限定名相同，都只会被加载一次。这样可以避免同一个类被多次加载，从而保证了类的唯一性和一致性。

如何打破双亲委派机制？

可以自定义类加载器，继承ClassLoader类，重写loadClass方法，因为在默认的loadClass方法实现中，遵循了双亲委派机制。要打破该机制，就需要修改这个方法的逻辑，不先委派给父类加载器，而是直接尝试自己加载类。

 

 

Spring、SpringBoot、SpringCloud

讲讲Spring中bean的生命周期？

### Spring 中 Bean 的生命周期是指从 Bean 被创建到销毁的整个过程，

Spring 容器通过构造函数或者工厂方法等方式创建 Bean 的实例。如果 Bean 有多个构造函数，Spring 会根据依赖关系选择合适的构造函数进行实例化。

Bean 实例创建完成后，Spring 会按照配置将 Bean 的属性值注入到相应的属性中。这可以通过注解或者 XML 配置来实现。

在Bean 属性赋值完成后，会执行BeanPostProcessor的方法，在 Bean 初始化之前对其进行一些额外的处理，例如修改 Bean 的属性值、检查 Bean 的状态等。

然后Spring 会调用 Bean 的初始化方法。可以通过注解或者实现InitializingBean接口来定义初始化方法。在初始化方法中，可以进行一些资源的初始化、数据的加载等操作。

Bean 初始化完后，会执行BeanPostProcessor的方法，对其进行进一步的处理，例如代理 Bean、添加额外的功能等。

经过前面的步骤后，就可以在应用程序中被使用了。此时，Bean 已经处于可用状态，可以被其他 Bean 依赖和调用。

当Spring 容器关闭时，会先调用DestructionAwareBeanPostProcessor的方法，在 Bean 销毁之前进行一些清理工作，如释放资源、关闭连接等。

最后，Spring 会调用 Bean 的销毁方法。可以通过注解或者实现DisposableBean接口来定义销毁方法。在销毁方法中，应该释放 Bean 占用的所有资源，以避免资源泄漏。

 

说说springboot自动装配原理?

Spring Boot 的自动装配原理本质上是通过 “约定优于配置” 的理念，让框架自动识别应用所需的配置并完成初始化，从而避免开发者手动编写大量样板代码。其核心机制围绕着启动类上的@SpringBootApplication注解展开，这个注解整合了@EnableAutoConfiguration、@ComponentScan等功能，其中@EnableAutoConfiguration是触发自动装配的关键 —— 它会借助AutoConfigurationImportSelector类去扫描META-INF/spring.factories文件，该文件中记录了所有可能的自动配置类，比如数据库连接、Web MVC 框架等相关配置。

 

这些配置类并非全部生效，而是通过@Conditional系列注解进行条件筛选。@ConditionalOnMissingBean会确保容器中没有用户自定义的同类 Bean 时才使用默认配置，@ConditionalOnProperty则根据配置文件中的属性值决定是否启用配置。这种条件化加载机制使得框架能根据应用的依赖和配置动态调整加载的配置项，避免无效配置的加载。

 

当符合条件的配置类被加载后，它们会在 Spring 容器中注册所需的 Bean。比如WebMvcAutoConfiguration会注册处理 HTTP 请求的相关组件，RedisAutoConfiguration会配置 Redis 连接工厂等。这些配置类还会通过@ConfigurationProperties绑定配置文件中的属性，让用户可以通过application.yml或application.properties轻松修改默认行为，比如调整端口号、数据库连接参数等。

 

同时自动装配有较高的扩展性，用户可以通过多种方式干预配置过程，这种设计既保证了框架的自动化能力，又为开发者保留了灵活定制的空间，使得 Spring Boot 既能快速启动应用，又能适应复杂的业务场景。

 

 

Jdk动态代理和cglib代理的区别？

代理机制不同，JDK动态代理基于接口，必须实现至少一个接口，CGLIB代理基于继承，通过继承目标类生成子类代理，性能不同，JDK动态代理创建快，无需生成新类，直接通过反射调用，但调用慢，每次调用需通过反射，性能更低。CGLIB代理创建慢，需生成子类字节码并加载，但调用快，直接继承父类方法，无需反射，性能较高。

以及代理机制决定了cglib可代理普通类的方法，但无法处理final类和方法。

 

 

Spring中关于数据库事务的传播方式有哪些？

必须使用事务

如果当前存在事务，则加入该事务；如果当前没有事务，则创建一个新的事务。这是 Spring 默认的事务传播方式。

支持事务

如果当前存在事务，则加入该事务；如果当前没有事务，则以非事务的方式执行。

强制使用事务

如果当前存在事务，则加入该事务；如果当前没有事务，则抛出异常。

新建事务

无论当前是否存在事务，都会创建一个新的事务。如果当前存在事务，则将当前事务挂起，直到新事务执行完毕。

不支持事务

以非事务的方式执行操作，如果当前存在事务，则将当前事务挂起。

绝不使用事务

以非事务的方式执行，如果当前存在事务，则抛出异常。

嵌套事务

如果当前存在事务，则在嵌套事务中执行；如果当前没有事务，则创建一个新事务，与PROPAGATION_REQUIRED类似。嵌套事务可以有多个保存点，当内部事务回滚时，只会回滚到最近的保存点，而不会影响外部事务。



 

讲一下Spring的ioc、aop、di？

· IoC 是一种设计思想，它将对象的创建和对象之间的依赖关系的管理从应用程序代码本身转移到了外部spring容器中。在传统的编程方式中，对象的创建和依赖关系的维护是由开发者在代码中直接进行的，这使得代码的耦合度较高，难以维护和扩展。而在 IoC 模式下，对象的创建和依赖关系的注入由容器负责，应用程序只需要从容器中获取所需的对象，而不需要关心对象是如何创建和依赖关系是如何解决的。

· 通过IoC，实现了对象之间的解耦，提高了代码的可维护性和可扩展性。使得组件的依赖关系更加清晰，便于代码的复用和单元测试。

DI 是IoC的一种实现方式。它是指在运行时，由容器将依赖关系注入到组件中，从而使组件能够正常工作。依赖注入有三种常见的方式，分别是构造函数注入、Setter 方法注入和接口注入。

构造函数注入可以确保依赖关系在对象创建时就被正确初始化，适用于对象的依赖关系在创建后不会改变的情况。Setter 方法注入则更加灵活，允许在对象创建后动态地设置依赖关系，适用于需要在运行时根据不同条件来设置依赖的场景。

AOP 是一种编程范式，它允许开发者将横切关注点从业务逻辑中分离出来，形成独立的切面，然后在运行时将这些切面织入到目标对象的方法执行过程中。

其中切面是一个模块化的横切关注点，它包含了一组相关的通知和切入点。例如，一个用于日志记录的切面可能包含了在方法执行前记录方法调用信息、在方法执行后记录方法返回结果等通知。

通知定义了在切入点处要执行的具体逻辑，包括前置通知、后置通知、环绕通知、异常通知和最终通知等类型。

切入点定义在哪些方法或代码块上应用切面的规则。可以通过方法签名、注解等方式来定义切入点。

使用 AOP 可以有效地减少代码的重复，提高代码的可维护性和可扩展性。将横切关注点与业务逻辑分离，使得业务逻辑更加清晰和简洁，同时也方便对横切关注点进行统一的管理和维护。

 

Spring Bean的作用域有哪些？

***\*单例\*******\*，\****Spring Bean 的默认作用域。在整个 Spring 容器中，无论在何处引用该 Bean，都只会存在一个共享的实例

***\*原型\*******\*，\****每次请求获取 Bean 时，Spring 容器都会创建一个新的实例。

***\*请求\*******\*，\****在一次 HTTP 请求中，Spring 容器会为该请求创建一个 Bean 实例，且仅在当前请求范围内有效。当请求处理完成后，该 Bean 实例会被销毁。

***\*会话\*******\*，\****在一个 HTTP Session 范围内，Spring 容器会创建一个 Bean 实例，该实例在整个 Session 期间有效。当 Session 过期或被销毁时，对应的 Bean 实例也会被销毁。

***\*应用\*******\*，\****在整个 Web 应用程序范围内共享一个 Bean 实例，类似于 ServletContext 级别。它在应用程序启动时创建，在应用程序关闭时销毁。

 

讲讲session、cookie、token？

Cookie 是由服务器发送到用户浏览器并存储在本地的一小段文本数据。它通常包含键值对，用于在用户访问网站时记录用户的相关信息。

当用户访问网站时，服务器可以通过设置Set - Cookie响应头来向浏览器发送 Cookie。浏览器会将 Cookie 存储在本地，之后每次向同一服务器发送请求时，都会在请求头中包含相应的 Cookie 信息，以便服务器识别用户身份和获取相关用户数据。浏览器会自动在后续请求中携带 Cookie，无需用户手动操作。

同时由于 Cookie 存储在客户端，容易被用户篡改或窃取，因此不适合存储敏感信息。

Session 是服务器端用于跟踪用户会话的一种机制。它通过在服务器内存或数据库中存储用户相关信息，为每个用户创建一个唯一的会话标识。

用户首次访问网站时，服务器会为其创建一个 Session，并生成一个唯一的 Session ID。服务器将 Session ID 通过 Cookie 发送给浏览器，浏览器在后续请求中会携带该 Session ID。服务器根据 Session ID 来查找对应的 Session 对象，从而获取用户的相关信息，实现对用户状态的跟踪。

数据存储在服务器端，相对安全，不会被客户端直接篡改。

能够有效地跟踪用户在整个会话期间的操作和状态变化。

但随着并发用户数的增加，Session 会占用服务器的内存资源，因此需要合理设置 Session 的过期时间，以释放不再使用的 Session 资源。

Token 是一种用于身份验证和授权的令牌，通常是一个加密的字符串。它包含了用户的相关信息，如用户 ID、权限等，用于在不同的系统或服务之间进行身份验证和数据传输。

用户在登录时，向服务器发送包含用户名和密码等凭证的请求。服务器验证用户身份后，生成一个 Token，并将其返回给客户端。客户端在后续请求中，将 Token 放在请求头或其他指定位置发送给服务器。服务器接收到请求后，通过验证 Token 的有效性来确定用户的身份和权限，从而决定是否允许用户访问相应的资源。

Token 中包含了用户的所有必要信息，服务器无需在内存中存储用户的会话状态，减轻了服务器的负担，便于实现分布式部署和扩展。

且Token 通常是经过加密和签名处理的，难以被篡改和伪造。同时，可以设置 Token 的有效期，一旦过期，需要重新获取 Token，提高了系统的安全性。

以及可以根据不同的需求，在 Token 中包含不同的信息，如用户角色、权限范围等，方便进行灵活的授权和访问控制。

 

 

说说你对循环依赖的认识?

### 循环依赖是两个或多个类相互引用，形成依赖关系的闭环。

### 会导致对象创建和初始化困难，在存在循环依赖的情况下，对象的创建和初始化过程可能会变得复杂且容易出错。因为每个对象都依赖于其他对象的先初始化，可能导致初始化顺序难以确定，甚至出现死锁情况，即两个或多个对象相互等待对方初始化完成，从而导致程序无法继续执行。

### 以及循环依赖会使代码结构变得复杂，难以理解各个组件之间的关系。当需要对代码进行修改、扩展或调试时，由于依赖关系的复杂性，可能会引发一系列意想不到的问题，增加了维护成本。

### 可以通过分析依赖关系，对代码进行重构，打破循环依赖。可以将一些公共的功能提取出来，形成独立的模块或类，让相互依赖的组件通过这个公共模块进行交互，从而避免直接的循环依赖。

### 或者使用依赖注入容器，帮助管理对象的创建和依赖关系。它可以按照一定的规则和顺序来初始化对象，并解决对象之间的依赖问题。例如，在 Spring 框架中，通过使用依赖注入，可以有效地解决类之间的循环依赖问题。

 

讲一下微服务中组件的作用，以及有哪些组件？

### 服务发现组件，允许微服务在运行时动态地发现彼此的位置和状态。它使得服务之间能够相互通信，而无需事先知道对方的具体网络地址。当一个微服务启动时，它会向服务发现组件注册自己的信息，包括服务名称、IP 地址、端口号等。其他微服务可以通过查询服务发现组件来获取所需服务的连接信息，从而实现服务间的调用。

### 配置中心组件，用于集中管理微服务的配置信息。它允许开发人员在不重新部署微服务的情况下，动态地修改配置参数。配置中心提供了一个统一的配置管理平台，使得配置的修改和分发更加便捷和高效，同时也保证了配置的一致性和安全性。

### 网关组件，作为微服务架构的入口点，它接收所有来自外部的请求，并根据请求的路径、参数等信息将请求路由到相应的微服务。网关还可以实现一些额外的功能，如请求过滤、身份验证、授权、限流、缓存等，从而为微服务提供统一的安全防护和性能优化。

### 熔断器组件，用于监控微服务之间的调用关系，当某个微服务出现故障或响应时间过长时，熔断器会自动切断对该服务的调用，以防止故障的扩散和级联效应。当故障恢复后，熔断器会自动恢复对该服务的调用。熔断器能够提高微服务架构的稳定性和可靠性，避免因单个服务的故障导致整个系统的崩溃。

### 监控组件，用于实时收集微服务的运行状态信息，如 CPU 使用率、内存使用率、请求响应时间、吞吐量等，以便运维人员及时了解系统的运行情况，发现潜在的问题并进行性能优化。

 

操作系统

进程和线程的区别是什么？

进程是资源分配的基本单位，而线程是 CPU 调度的基本单位。进程有独立的地址空间，一个进程崩溃不会影响其他进程。线程共享进程的地址空间，一个线程崩溃可能导致整个进程崩溃。

进程的创建、切换和销毁开销较大，线程的开销相对较小。

 

进程和线程分别有什么通信方式？

进程的通信方式有管道、消息队列、共享内存、信号量、套接字，线程的通信方式则有共享内存、条件变量、信号量、互斥锁。

 

什么是死锁？产生死锁的原因和必要条件是什么？

死锁是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞的现象，若无外力作用，它们都将无法推进下去。

产生死锁的原因主要有资源竞争和进程推进顺序不当。产生死锁的必要条件有资源非共享一次只有一个进程可以使用、一个进程至少占有一个资源并等待另一个资源、资源不能被抢占、进程间互相循环等待。

 

怎么避免死锁？

系统动态监测可能导致死锁的情况，避免进入死锁状态，比如每次资源申请时判断分配后系统是否仍处于安全状态，如果资源分配会导致死锁则拒绝该请求，常用资源分片图算法和等待图算法来检测，以及如果检测到死锁可以通过中止进程、回滚进程状态、强行从其他进程抢占资源重新分配等方式解除死锁。

 

什么是IO多路复用？

IO多路复用是一种高效的IO模型，允许单个线程同时监听多个文件描述符，并在某个文件描述符可读、可写或出现异常时得到通知。这样可以避免无效的等待，充分利用CPU资源。常用的有select、poll、epoll模式，其中epoll相比于poll和select，能支持更大的并发连接数、性能更高。

 

什么是用户态、内核态？

用户态是指应用程序运行在非特权模式下的状态，此时应用程序只能访问被授权的资源，不能直接操作硬件资源和底层系统资源。在用户态下，应用程序只能执行一些受限的指令集，不能直接执行特权指令。

当应用程序需要访问系统资源时，需要通过系统调用的方式切换到内核态，请求操作系统提供服务。内核态和用户态之间的切换是通过操作系统内核提供的中断或异常机制实现的。

内核态是操作系统运行在特权模式下的状态，此时操作系统具有最高的权限，可以访问所有的硬件资源和底层系统资源，如处理器、内存、I/O等。在内核态下，操作系统可以执行所有的指令，而且不受访问权限的限制。

 

常见的进程调度算法有哪些？

有先来先服务，非抢占式，按照请求的顺序进行调度。 最短作业优先，非抢占式，按估计运行时间最短的顺序进行调度。 最短剩余时间优先，最短作业优先的抢占式版本，按剩余运行时间的顺序进行调度。 

时间片轮转调度，将所有就绪进程按 FCFS 的原则排成⼀个队列，每次调度时，把 CPU 时间分配给队首进程，该进程可以执行一个时间片。当时间片用完时，由计时器发出时钟中断，调度程序便停止该进程的执行，并将它送往就绪队列的末尾，同时继续把 CPU 时间分配给队首的进程。 

优先级调度，为每个进程分配一个优先级，按优先级进行调度。

 

什么是孤儿进程，什么是僵尸线程，如何处理僵尸线程？

1孤儿进程指的就是一个进程的父进程已经退出或者终止了，但是这个子进程本身还在运行的情况，僵尸进程指的是一个进程已经退出，但他还存在于进程表。

僵尸进程仍占据着系统的某些资源如进程号，可以通过清除僵尸进程的父线程、重启僵尸进程所属的服务来清理僵尸线程。

 

什么是内存管理？

内存管理分为连续内存管理和非连续内存管理，其中连续内存管理为一个用户程序分配一个连续的内存空间，内存利用率一般不高，容易造成内存碎片

非连续内存管理允许一个程序使用的内存分布在离散的内存中，相对更加灵活一些。

有段式管理，将应用程序的虚拟地址空间划分为多个逻辑段，每个段是一段连续的物理内存，有页式管理，把物理内存分为连续等长的物理页，应用程序的虚拟地址空间也被划分为连续等长的虚拟页，有段页式管理，结合了段式管理和页式管理，把物理内存先分成若干段，每个段又继续分成若干大小相等的页。

 

 

计算机网络

说下OSI 七层模型？  

**1.** ***\*物理层\****：是 OSI 模型的最底层，主要负责处理物理介质上的信号传输，确保数据能够在物理介质上进行可靠的传输。

**2.** ***\*数据链路层\****：主要功能是将物理层接收到的原始比特流转换为有意义的数据帧，并进行错误检测和纠正

**3.** ***\*网络层\****：负责在不同的网络之间进行数据路由和转发，使数据能够从源节点到达目标节点，还负责处理网络拥塞、数据包分片和重组等问题。

**4.** ***\*传输层\****：主要为应用程序提供端到端的通信服务，确保数据在不同主机之间的可靠传输，常见的协议有 TCP和UDP。

**5.** ***\*会话层\****：用于建立、维护和管理会话连接，协调不同主机上应用程序之间的通信。它可以实现会话的同步、断点续传等功能，确保通信双方能够按照正确的顺序进行数据交换。

**6.** ***\*表示层\****：主要负责处理数据的表示和转换，包括数据加密和解密、压缩和解压缩、字符编码转换等。它确保不同系统之间能够正确地理解和处理数据，使应用层能够专注于数据的语义和逻辑处理。

**7.** ***\*应用层\****：是 OSI 模型的最高层，直接面向用户和应用程序，为用户提供各种网络服务，应用层的协议规定了应用程序如何与网络进行交互，以实现特定的功能。

 

 

讲讲tcp、udp、http、https等网络协议？

TCP是一种面向连接的协议，在数据传输之前需要先建立连接，传输完成后再释放连接。通过三次握手建立连接，确保通信双方都做好了数据传输的准备；通过四次挥手来释放连接，保证数据传输的完整性。

具有高可靠性，它通过序列号、确认应答、重传机制等保证数据的准确传输。如果发送方发送的数据在规定时间内没有收到接收方的确认应答，就会自动重传数据，直到接收方正确接收为止。

能够进行流量控制，通过滑动窗口机制让发送方根据接收方的接收能力来调整发送数据的速度，防止接收方缓冲区溢出。还具备拥塞控制机制，当网络出现拥塞时，自动降低发送数据的速率，以避免网络进一步拥塞。

UDP是一种无连接的协议，发送方不需要事先与接收方建立连接就可以直接发送数据。这种方式使得 UDP 的传输速度较快，但不保证数据一定能准确到达接收方，没有确认应答、重传等机制。数据发送出去后，发送方不知道数据是否被正确接收，也不会主动去处理数据丢失或错误的情况。

具有低延迟、高效率的特点，因为它不需要像 TCP 那样进行复杂的连接建立和维护操作，也没有流量控制和拥塞控制机制，所以在传输小数据量、对实时性要求较高的场景中表现出色。

HTTP是一种应用层协议，主要用于在 Web 浏览器和 Web 服务器之间传输超文本数据，如 HTML 页面、图片、视频等。它规定了客户端和服务器之间数据交互的格式和规则。

采用请求 - 响应模式，客户端向服务器发送请求，服务器接收到请求后进行处理，并向客户端返回响应。请求和响应消息都包含报头字段和消息体，报头字段用于传递一些元信息，如请求方法、数据类型、缓存策略等，消息体则包含了实际传输的数据。

具有无状态性，即服务器不会在不同的请求之间记住客户端的状态信息。每个请求都是独立的，服务器只根据当前接收到的请求进行处理并返回响应，不依赖于之前的请求或交互历史。

通常基于 TCP 协议来实现，默认使用 80 端口进行数据传输。在建立连接后，客户端和服务器通过 TCP 连接进行 HTTP 数据的传输。

HTTPS实际上是 HTTP 协议与 SSL/TLS协议的结合，在 HTTP 的基础上增加了加密和认证功能，确保数据在传输过程中的安全性和完整性。它通过 SSL/TLS 协议对数据进行加密，使得数据在网络传输过程中变成密文，只有合法的接收方才能解密和读取数据。

利用数字证书来进行身份认证，服务器会向客户端提供由权威证书颁发机构颁发的数字证书，客户端可以通过验证证书来确认服务器的身份是否可信。这可以防止中间人攻击，确保客户端连接到的是真正的目标服务器，而不是被假冒的服务器。

默认使用 443 端口进行数据传输。由于增加了加密和解密等操作，HTTPS 的性能相对 HTTP 会稍低一些，但随着硬件性能的提升和加密算法的优化，这种性能差异在大多数情况下并不明显，而且其安全性优势远远超过了性能上的损失。

 

讲讲三次握手？

第一次握手：客户端向服务器发送一个 SYN同步报文段，该报文段中包含客户端随机生成的初始序列号x。此时客户端进入同步已发送状态，表明客户端希望与服务器建立连接，并已准备好发送数据。

第二次握手：服务器接收到客户端的 SYN 报文段后，会向客户端发送一个 SYN+ACK 报文段。其中，SYN 表示同步，ACK 表示确认。服务器会为自己生成一个初始序列号 y，并将客户端的序列号加 1 作为确认号x+1。此时服务器进入同步已接收状态，表明服务器已收到客户端的连接请求，并同意建立连接。

第三次握手：客户端收到服务器的 SYN+ACK 报文段后，会向服务器发送一个 ACK 报文段。客户端将服务器的序列号加 1 作为确认号y+1，自己的序列号则为 x+1。服务器收到这个 ACK 报文段后，连接建立成功，双方进入建立连接状态，此时客户端和服务器就可以开始进行数据传输了。

 

TCP为什么3次握手，两次行不行？

TCP 三次握手是为了确保通信双方都能确认彼此的发送和接收能力，建立可靠的连接。两次握手不行，因为如果只有两次握手，服务器在第二次握手时发送的确认信息无法确定客户端是否能够成功接收，无法确认客户端接收能力。

比如，客户端发送的第一次握手请求丢失，客户端会认为服务器没有收到请求而重新发送请求。

但服务器在收到第二个请求后会认为客户端是第一次发送请求，于是发送确认信息并建立连接。

然而，如果这个确认信息在传输过程中丢失，服务器会认为连接已经建立并开始发送数据，而客户端由于没有收到确认信息，不会认为连接已建立，从而导致数据丢失，连接建立失败。

且易造成资源浪费，比如客户端发送的第一次握手请求丢失，客户端会认为服务器没有收到请求而重新发送请求，以及服务器在收到客户端的连接请求后就会为该连接分配资源，如果客户端因为某些原因不再发送数据，服务器就会一直等待，造成资源浪费。

而三次握手可以避免这种情况，因为只有客户端收到服务器的确认信息并发送第三次握手的确认后，双方才真正建立连接并开始分配资源。

 

讲讲四次挥手？

第一次挥手：客户端向服务器发送一个 FIN 结束报文段，该报文段中包含客户端当前的序列号 x，用于告知服务器自己不再发送数据，但仍可接收数据，。此时客户端进入终止等待 1状态，标志着客户端主动发起连接断开请求。

 

第二次挥手：服务器接收到客户端的 FIN 报文段后，会向客户端发送一个 ACK 确认报文段。服务器将客户端的序列号加 1 作为确认号 x+1，自己的序列号为 y。此时服务器进入关闭等待状态，表明服务器已收到断开请求，正在处理剩余数据；客户端收到 ACK 后，进入终止等待 2状态，等待服务器完成数据传输。

 

第三次挥手：当服务器处理完所有剩余数据后，向客户端发送 FIN 结束报文段，其中序列号为 y+1，确认号仍为 x+1。此时服务器进入最后确认状态，表明自己也不再发送数据，等待客户端的最终确认。

 

第四次挥手：客户端接收到服务器的 FIN 报文段后，向服务器发送 ACK 确认报文段。客户端将服务器的序列号加 1 作为确认号 y+2，自己的序列号为 x+1。发送后，客户端进入时间等待状态，服务器收到 ACK 后，直接进入关闭状态，连接正式终止。

 

Tcp为什么四次挥手？

关闭连接时，客户端向服务端发送FIN报文，仅表示客户端不再发送数据，但还能接受数据

而服务端收到客户端的FIN报文后，先回一个ACK报文，而服务端可能还有数据需要处理和发送，等到服务端处理完毕，再发送一个FIN报文给客户端

服务端通常需要等待数据完成处理和发送，所以服务端的ACK报文和FIN报文是分开来发送的，总计四次

 

 

http状态码有哪些，代表的意义？

### ***\*常见的有\****

### 2xx 成功状态码

200 OK：请求成功，服务器已成功处理了请求并返回了请求的资源。

201 Created：请求成功，并且服务器创建了新的资源。

202 Accepted：服务器已接受请求，但尚未处理完成。该请求可能在后台进行处理。

204 No Content：请求成功，但服务器没有返回任何内容。通常用于只需要执行服务器端操作而不需要返回数据的情况。

### ***\*3xx 重定向状态码\****

301 Moved Permanently：请求的资源已被永久移动到新的 URL。客户端应使用新的 URL 进行后续请求。

302 Found：请求的资源临时位于不同的 URL。客户端应使用新的 URL 进行本次请求，但后续请求仍可使用原 URL。

303 See Other：服务器建议客户端通过另一个 URL 获取资源，通常用于 POST 请求后，让客户端重定向到一个 GET 请求的 URL 以获取结果。

304 Not Modified：客户端发送了附带条件的请求，且服务器认为资源未被修改，客户端可以使用缓存的资源。

### ***\*4xx 客户端错误状态码\****

### 400 Bad Request：客户端发送的请求有错误，服务器无法理解请求的语法。

### ·401 Unauthorized：客户端请求需要身份验证，而客户端未提供有效的身份凭证或凭证无效。

### ·403 Forbidden：服务器理解请求，但拒绝执行该请求。客户端可能没有足够的权限访问请求的资源。

### ·404 Not Found：服务器无法找到请求的资源。可能是 URL 输入错误或资源已被删除。

### ·405 Method Not Allowed：客户端请求的方法（如 GET、POST 等）不被服务器允许用于请求的资源。

### ***\*5xx 服务器错误状态码\****

·500 Internal Server Error：服务器内部发生错误，无法完成请求。这是一个通用的错误代码，通常表示服务器端出现了未预料到的问题。

·501 Not Implemented：服务器不支持请求中所使用的功能或方法。

·502 Bad Gateway：服务器作为网关或代理，从上游服务器接收到了无效的响应。

·503 Service Unavailable：服务器暂时无法处理请求，通常是由于服务器过载或正在维护。

·504 Gateway Time - out：服务器作为网关或代理，在等待上游服务器响应时超时。

 

网页URL输入到浏览器上的流程？

浏览器首先检查自身的缓存，看是否有该 URL 对应的 IP 地址缓存。如果没有，就会向操作系统的 DNS 缓存查询。若操作系统的 DNS 缓存中也没有，浏览器会向本地配置的 DNS 服务器发送请求，进行域名解析，获取 URL 对应的 IP 地址。

获取IP后浏览器与目标服务器通过 TCP 协议进行连接，连接建立后，浏览器会根据输入的 URL 生成 HTTP 请求报文，包括请求方法、请求头字段以及请求体，并将其发送到服务器。

服务器接收到 HTTP 请求后，根据请求的 URL 和其他信息进行处理，可能会涉及到查询数据库、执行脚本等操作，以生成响应内容。

服务器将生成的响应内容封装成 HTTP 响应报文，包括响应状态码、响应头字段以及响应体，并发送给浏览器。

然后浏览器接收并解析 HTTP 响应报文，提取出 HTML、CSS、JavaScript 等资源。

浏览器根据这些资源生成渲染树，再根据渲染树进行布局和绘制，将页面呈现给用户。

 

https加密流程？

客户端向服务器发送一个 HTTPS 请求，请求中包含客户端支持的加密算法、密钥交换算法等信息。

服务器收到客户端请求后，根据客户端提供的信息，选择一种双方都支持的加密算法和密钥交换算法，并将服务器的数字证书发送给客户端。

客户端收到服务器的数字证书后，会验证证书的合法性，如果证书验证通过，客户端会从证书中提取出服务器的公钥。客户端使用服务器的公钥对一个随机生成的会话密钥进行加密，并将加密后的会话密钥发送给服务器。这个会话密钥将用于后续的加密通信。

而服务器使用自己的私钥对客户端发送的加密会话密钥进行解密，得到会话密钥。当通信结束后，客户端和服务器会关闭连接。在关闭连接之前，双方可以协商是否需要重新进行密钥交换，以便进行下一次的加密通信。

 