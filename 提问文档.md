流程记忆方式：具体是做什么+分片上传和断点续传怎么实现

分片上传和断点续传

你简历中有写使用了分片上传和断点续传，那么讲一讲分片上传和断点续传是怎样的？

1. 分片上传要做的是将一个完整的视频拆成分片同时间执行多次上传并在上传完成后合并分片成完整文件，断点续传是确保上传中断情况下重新上传能只上传未上传过的分片，而不上传已上传过的部分。
2. 原先实现方式是前端会将原始文件拆分成多个小分片，

同时启动多个线程，每个线程都会对应一个分片，先发请求查询该文件的该分片之前是否已经上传过，响应通知上传过那么后续上传分片操作就不执行

3. 通知没上传过发请求上传分片和总的片数到后端，后端每次接收文件分片后用特定文件名做键，记录该文件已经上传的分片索引的集合做值，将文件上传状态存到map中，若接收完分片后发现文件已上传的分片数量等于总的分片数则执行合并操作，这样就能利用多线程同时上传多个分片加快文件上传速度，同时保证因为网络波动或其他原因导致的上传中断后重新上传分片时，同一个已上传分片不再上传。
4. 上传文件和保存新视频信息到数据库被拆成了两步，上传最后一个分片的请求得到的响应中会有合并后的视频存储在minio中的地址，用户将视频标签视频简介填写好、选择一个文件做封面，然后选择上传按钮将视频标签、简介、封面文件流、视频存储在minio中的地址发送给后端，后端将封面上传到minio并存储封面在minio中的地址，再将这些视频信息保存到mysql，并移除map中该文件对应的键值对

5.项目中使用mysql存储文件的话性能不高且上传下载需要做额外的转换，因此采取了对象存储服务，而minio可以用于存储文件对象，因此选择minio，不选择oss的原因是minio无成本，只需要自己部署。 

6.但这种方案上传速度仍然可以优化，我的想法是后端可以用于提供一个安全凭证，上传文件时前端向后端发送请求获取一个可以临时和minio交互的令牌，用该令牌做凭证直接将分片上传到minio和执行合并，这样可以省去从前端传输到后端的时间，临时令牌也保证了上传权限不会被客户端长久持有，但上传文件内容无法在minio端进行解析，因此会有被上传恶意文件的可能，所以如果更看重性能可以选前端直接连minio，更看重安全性可以用原项目方法。

 

辅助记忆

1.分片上传和断点续传是要做什么

2.分片上传前的查询

3.查出分片没上传过后的操作

4。补充完整数据库视频相关信息

5.使用minio的原因

6其他优化方案

 

上传选择封面是强制的吗？如果是的话我现在改成不强制，应该怎么保证视频还是有封面？

是的。可以在上传环节中保存视频数据到数据库的接口里做检测，如果封面文件流是空的则用视频存储在minio中的地址去下载完整文件流，然后调用工具库剪切下来一帧图片作为封面文件。

 

你提到有特定文件名，那么该文件名如何生成？会出现两个不同的文件的特定文件名重合的情况吗？如果会的话如何应对？

由文件的修改时间加文件名组成。有可能出现，可以在特定文件名后再加随机生成的uuid或者加上原始文件的哈希值让不同的文件撞名字概率大大降低。

 

 

在分片上传过程中，如果某个分片上传失败，应该怎么处理？

分情况考虑，如果前端网络波动等原因导致前端无法将分片传递给后端，则前端恢复后执行断点续传流程

若连接不上后端则前端持续重试直到较多次数后放弃重试，通知用户上传失败

若是服务端上传minio过程失败则服务端进行对minio的上传重试

若多次重试仍失败则响应通知前端上传失败，保证只有所有分片都上传成功了才能执行下一步将视频信息和视频实际存储地址传给后端，保存新视频数据到mysql中。

 

还可以别的方式实现分片上传和断点续传吗？如何实现极速秒传？

1.后端将前端传递的完整文件分片并启动多个线程上传到minio，这种方式安全性更高，不暴露minio地址且可以先提前审查文件是否是恶意文件，但速度没有前端直传快

2.或者前端分片后发送请求从后端获取一个临时凭证，然后携带这个凭证直接连接minio不经过后端中转，这样虽然会暴露minio地址，但可以通过对minio的设置来限制上传时必须要带凭证且速度比较快，但无法审查出恶意文件

3.断点续传则是可以客户端记录已上传分片的索引集合，而不是服务端记录，这样服务端存储压力更小，但客户端相比服务端可靠性可能会更低

4.极速秒传则是给视频表加一列用来存视频的哈希值，每次上传视频之前会前端计算当前视频的哈希值出来，发送请求将值传给后端，这个请求对应的后端接口会查询视频表是否有相同哈希值的记录。

没有的话就正常上传并且把视频的哈希值存到视频表中，如果查询到有那么就把这个相同哈希值的视频的实际存储地址返回前端，并且页面上显示上传进度条拉满，直接完成上传。

 

辅助记忆

1.后端接收完整文件并分片上传以及优缺点

2.前端从后端拿凭证后直连minio以及优缺点

3.断点续传客户端记录分片上传状态

4.极速秒传实现

 

已上传分片的记录存储在内存Map中，若服务器重启，如何保证断点续传的可靠性？

内存map依赖于服务器，那么找到一个不依赖服务器的存储位置可以保证断点续传的可靠性，可以将已上传分片的记录存储位置改到redis中。

 

 

​    

 

如果要加个视频下载功能，你如何设计？

可以让前端用初始化播放页面时，请求拿到的视频存储在minio的地址去下载完整文件，

也可以简单的发送请求，后端从minio中获取对应视频的完整文件流再返回给前端

也可以再优化，后端获取完整文件流后分片返回前端，让前端进行聚合，提升下载速度

还可以再优化，将上传分片时前端传来的分片利用起来，这样的话新建一个表记录某个视频和该视频的分片实际存储minio中的地址

在某个分片上传后向该表中存储一条新记录绑定该视频和视频的一个分片实际存储地址，下载一个视频时从该表中查出对应的分片实际存储地址后多线程下载多个分片再将多个分片返回前端，由前端执行分片聚合。

 

有没有评估过在线播放支持多少人使用?

没有，但如果要评估的话思路是将QPS不断拉高，直到服务宕机，这个导致服务宕机的QPS数就是在线播放支持多少个人使用的上限。

 

假如有个视频网站原型，多人看视频加载不了，如何排查分析?

从加载视频的完整流程进行分析，前端发送请求到后端

后端查询数据库并得到视频存储在minio中的地址，将该地址返回前端

前端用该地址请求minio获取视频资源，若是前端请求后端失败则可能是后端服务宕机或后端接口出问题

若后端服务正常运行则看数据库是否连接失败了

若连接无误则查看数据库查询sql是否有误，若也无误则看数据库中存储的视频存储在minio中地址是否有误。

 

如果同时有特别多用户同时上传视频，导致java内存占用过多，你该怎么办？

可以让前端在将原始文件分片前先压缩原始文件降低文件大小

可以启动多个视频服务的实例做负载均衡来减低单个视频服务实例的负担

还可以控制上传视频数，设定一个值，最大只能上传多少个视频，当前正在上传的视频数到达这个值后就阻塞剩余的上传线程直到正在上传视频数减少到小于这个值。

 

同时上传过多视频导致服务器宕机怎么办？

宕机后需要运维来重启服务器，后端能做的则是提前设计预防宕机方案，可以在上传完一个视频后手动清理视频缓存，使内存占用更快被释放

可以让前端在将原始文件分片前先压缩原始文件降低文件大小

可以启动多个视频服务的实例，多个实例运行在不同的服务器上，做负载均衡来减低单个服务器的负担

还可以控制上传视频数，设定一个值，单个服务实例最大只能上传多少个视频，当前正在上传的视频数到达这个值后就阻塞剩余的上传线程直到正在上传视频数减少到小于这个值。

 

 

一对一实时私聊

说说基于服务端中转架构的一对一实时私聊如何实现的？

1. 一对一实时私聊是当发送消息和接收消息的双方同时在线时，发送方发出消息后，消息立刻就会显示在接收方聊天页面。
2. （原先）实现方式是每个客户端进聊天页面后向后端发送w**e**bsocket连接申请，后端同意连接后会创建一个websocket对象代表这次连接，使用这个对象可以从后端向这次连接的客户端发送websocket消息

3.建立连接后客户端会发送websocket消息，将当前客户端userid传递给后端，后端调用处理websocket消息的方法，将当前客户端的userid和代表这次连接的websocket对象存到map中，初始化步骤完成

4.若后续有其他客户端要向当前客户端发送消息只需要将消息内容、其他客户端的userid和当前客户端的userid放到一起发送websocket消息给后端，后端调用处理websocket消息的方法，在map中查询当前客户端对应的websocket对象，查找到后用该对象从服务端向当前客户端发送websocket消息，从而实现消息的转发。并且每次有客户端的websocket消息进入后端都会保存聊天内容到数据库做持久化。

5当用户离开聊天页面后会关闭websocket连接，后端也会同步删除map中该用户对应的键值对，及时更新用户会话状态。

6.我觉得还可以用http的形式，定时任务发送请求获取最新的聊天内容，将定时任务间隔时间设置的较短来达到近似实时通信的功能，但这种方式需要频繁发送请求，对服务器负担可能过重，或者用sse服务端单向推送的技术，整体流程类似websocket，对服务端负担更小，但实现更复杂。

 

辅助记忆

1.实现效果

2.后端怎么向前端发送websocket消息

3.前端向后端发送消息，完成初始化

4.后续消息如何转发

5.清理会话

6.优化方案

 

 

如果我现在要扩展成多对多的实时私聊，应该如何实现？

1.创建消息表、群聊表和关联用户与群聊表的中间表，消息表有群聊id和发送人id和消息内容字段，群聊表有群聊名称群聊id，关联中间表有群聊id和用户id字段

2.进入页面时会发请求拉取群聊列表，用户增删改群聊会对群聊表进行修改，当用户需要加入某个群聊时，可以通过输入群号或群名称的形式先搜寻到群，再选择加入，然后对用户群聊中间表进行新增

3.有新消息发送到某个群时则往消息表新增记录，最后客户端执行较短间隔的定时任务定期从服务端拉取用户所在群的群聊消息和群聊状态来更新页面。

4.如果是websocket的形式则在进入聊天页面时建立websocket连接，并拉取当前用户的群聊列表，还是需要建立前面的表，新增群聊则发送请求更新数据库，同时新增修改删除群聊的websocket消息类型，当用户发送修改删除群聊的携带有群id的websocket消息时

将消息发送给在该群且在线的其他客户端来实时同步状态，同时持久化群聊情况到数据库

当用户需要加入某个群聊时，也是通过输入群号或群名称的形式先搜寻到群，再选择加入，并新增新入群的websocket消息类型，有新入群的用户时发送websocket消息给服务端，服务端同步给在该群且在线的其他客户端，同时持久化到数据库

同理，新增群聊消息的websocket消息类型，若有聊天消息则服务端将消息转发给在该群且在线的其他用户并持久化到数据库。

 

辅助记忆

1.创建的表和表字段

2.群聊增删改查以及加入群聊的实现

3.群聊消息发送以及状态更新实现

4.如果是websocket形式怎么实现前面流程

 

是用的什么进行的websocket连接管理？如果服务重启，如何恢复用户会话？ 

Java的hashmap。由于服务端无法主动向客户端发起websocket连接，那么要在服务重启时不丢失用户会话，可以把保存会话的map放到redis中，这样服务重启就不会影响到用户会话。

 

 

如果客户端异常断连，服务端如何主动清理残留的Session对象？

定时任务定期检查使用map中的websocket对象发送消息会不会报错，如果会的话那就说明连接断开了，或者在某一次转发websocket消息时监测到连接断开，那么将异常的websocket对象所对应的键值对进行删除。

 

 

在使用服务端中转的架构设计实现用户一对一实时私聊时，如何避免消息丢失？

后端转发websocket消息的同时将私聊内容持久化到mysql数据库。

 

若要为私聊功能添加消息撤回功能，请你给出实现思路？

Websocket消息在原先的初始化类型、大模型类型、聊天内容类型之外加一种撤回类型

同时每条消息都绑定一个id ，一端选择撤回时也发送websocket消息给后端，根据该消息的id删除数据库中的记录，并转发一条撤回消息给另一个客户端，让另一个客户端页面上删除对应id的聊天消息。

 

私聊如何保证消息有序性？

1.私聊出现乱序的情况应该是部署了多个聊天服务实例的情况下

比如两个实例负担不一样重，先发出去的聊天消息进入了负担重的实例，后发出去的聊天消息进入了负担轻的实例，负担轻的实例处理速度更快，导致后面的聊天消息反而先存入数据库，后面的聊天消息反而先转发给客户端

2.可以在gateway服务中建立一个全局的websocket过滤器和一个记录每个用户所分配实例的键为用户id值为实例名的map，每次有websocket消息过来时，用该websocket消息中的用户id去map中查询是否已有绑定的聊天服务实例

若有则直接转向该实例，若无则随机选择一个实例转向，并往map中新增记录，用这种形式实现同一个用户的websocket消息只由同一个实例处理，进而保证消息有序性。

 

辅助记忆

1.出现乱序的原因

2.用gateway建立全局过滤器保证同一个用户的消息由同一个实例处理

有大量用户在使用私聊功能的情况如何应对？

1.启动多个私聊服务做负载均衡来增强私聊功能的可承受并发量

2.若不修改服务器配置的情况可以修改springboot线程池配置，项目中接收websocket消息后的高频事件是将聊天消息插入数据库和转发消息给另一个客户端，属于I/O密集型，因此可以配置核心线程数为n*2来提升线程池效率

3.同时可以先测试临界值，看后端1s内的websocket消息处理数是多少时服务器会宕机

4.改造原有websocket消息，在原先发送websocket消息步骤前加一条websocket消息的发送，这条消息负责在后端查询当前有多少个正在处理的websocket消息并返回客户端，若客户端得到的值大于等于临界值值则先阻塞websocket消息的发送，这样可以避免流量过大服务器宕机

并轮询查询该值直到该值小于特定值，将阻塞的线程解开发送websocket消息出去，而后端每次处理一条websocket消息前先给当前处理数加一，处理完后给值减一，同时启动一个定时任务每秒将当前处理数重置为0.

5.聊天消息的持久化也可以不在每次有聊天消息类型websocket消息来时进行，可以缓存起来然后定期批量保存到数据库提升效率。

以及合理设置连接的超时时间，对于长时间无活动的连接进行及时清理，释放资源。

 

辅助记忆

1.负载均衡

2.修改线程池配置

3.临界值的确认

4.限流方案以及好处

5.批量持久化到数据库和定期清理无用连接

 

怎么设计一个私聊的拉黑功能？

建立一张表，表的列有拉黑人id和被拉黑人id，用户A拉黑用户B则向表中新插入一行拉黑人id为用户Aid，被拉黑人id为用户Bid的记录，用户B向用户A发送私聊消息前先查询拉黑表中是否有被拉黑人id为用户Bid，拉黑人id为用户Aid的记录，若有则发送失败，用户A取消拉黑用户B则是删除表的对应记录。

 

用户上线后是怎么收到离线消息的消息通知的？

上线后会查询消息表里状态为未读的消息数量，若不为0则前端会渲染出带未读消息数的红色数字，用户看到后点击图标可以跳转到私聊页查看未读消息。

 

统一授权、鉴权和单点登录

说说你项目里的统一授权鉴权和单点登录是怎么做的？

项目由六个服务组成，所有请求都统一进入网关服务进行鉴权

若请求路径在放行路径内则直接放行，路由转向实际业务服务

若不在放行路径则检验是否有合法且未过期的token

有则放行并将请求路由转向实际业务服务

无则返回401状态码提示前端该用户需要登录

同时网关服务负责登录注册，登录成功后授权，返回有效token给前端用于后续请求的鉴权

这样就避免了在每个业务服务重复编写鉴权授权功能代码

同时因为请求先在网关鉴权再转向其他服务，只需在网关服务登录过一次拿到token即可在访问其他服务时都保持登录状态，实现单点登录。

 

双token实现无感刷新

你简历中提到双JWT实现无感刷新token，说说这个流程？

1. 项目中原先采用的是token鉴权，jwt作为具体token实现形式，而jwt会有过期时间，设置的过长被盗用后造成的影响会更大，但设置的短又会出现用户进入网站一段时间后token就过期了，过期后的访问鉴权不通过会通知用户重新登录，影响用户体验
2. 因此选择单token进行无感刷新，设置过期时间为30min，前端每25min发送一次携带有效token的请求，获取新的过期时间为30min的token，这样在用户进入网站并登录后就可以一直保持登录态，且前端会在每次打开网页时发送一次刷新token请求，以此做到即使关掉了网站的所有页面，只要在30min内重新打开网站即可续上token
3. 但因为刷新token接口为了防止被恶意盗刷需要请求中存在有效token才能执行成功，还是会出现超过一定时间比如两天后token过期，再打开网站后的刷新token请求失败，登录态失效的问题，因此做了长短token，30min过期的短token只用于鉴权，7天的长token用于刷新token请求时的凭证，每次刷新请求只要存在有效的长token即可通过，返回新的30min过期短token，同时考虑到若长token过期时间不更新则会出现过了即使频繁进入网站，从登录时刻开始过了七天后仍然会有登录态失效的问题，因此选择在刷新短token同时刷新长token，以此做到只要七天内登录过一次即可无感刷新token。
4. 我觉得还可以用单token滑动+过期的形式，将用户token存到redis中，设置缓存七天过期，每次用户请求到后端时都会检验，若有对应token的缓存则说明token未过期

将token的对应缓存的过期时间设置到请求时间的七天后并放行请求，若无对应token的缓存则说明token已过期，提示前端重新登录，这样也可以实现无感刷新token

且可以少存储一个长token，复杂度降低，但相比双token流程单token用作鉴权的凭证双token用作刷新token的凭证，单token把鉴权和刷新权限耦合到一起了，没有进行很明确的职责拆分。

 

辅助记忆

1.最初不自动刷新方案

2.单token刷新方案

3.双token刷新方案

4.优化方案和优缺点

 

 

你说前端每25分钟发送一次刷新token请求，如果同时发起多个刷新请求（如网络延迟导致请求堆积），如何避免短时间内重复刷新（比如1分钟刷新几百次）？

每次发送请求前先查询redis中是否有刷新token请求对应的键值对，没有的话则发送一次请求，并且redis中设置个1分钟过期的值类型键值对，如果有的话就请求失败，通过这样将请求频率限制在最高1分钟1次。

 

 

若刷新 token 被泄露，可能会带来哪些安全风险，你在项目中采取了什么措施来防范这些风险？  

1.被恶意网站或者用户盗刷token的风险。

2.一个是可以添加设备指纹，给每个登录的用户返回一个存在http-only-cookie里的，用uuid来取值的设备指纹，刷新长token的请求会额外校验用户的设备指纹是否存在且合法

若不满足条件则说明是被窃取了长token来发送的请求，当次请求不会通过，这样盗刷token需要将长token和设备指纹一起盗取才能成功，增大了盗取难度

3.一个是可以在返回前端长token时在长token中存一个userid，用户每次访问接口时根据用户的真实ip调用api获取到用户的所在省市并保存到redis中，userid做键，真实省市做值，每次长token的刷新请求都会从redis中查询该用户的省市

再根据这次请求的ip地址去调api获取这次请求的发起者所在省市，若值不匹配则说明被窃取了，刷新请求会失败

同时根据ip做校验的方式如果用户使用了代理登录网站会出现误伤的情况，但这种情况出现概率小，而根据ip做校验确实是有效加强长token安全性的方法，如果权衡之下安全性更重要就可以采用

 

辅助记忆

1. 有哪些风险
2. 添加设备指纹和设备指纹赋值，存哪里，怎么用
3. 记录每次请求的真实ip以及什么情况适合用

 

设备指纹存在哪？多久过期？

http-only-cookie。可以仿照无感刷新流程，设置为七天过期，每次有请求都返回一个新的七天过期的设备指纹给前端。

 

 

长短token存储在那里的？

http-only-cookie里。

 

在实际应用中，双 JWT 无感刷新 token 的机制是否会受到服务器时间同步问题的影响？如果受到影响，你是如何解决的？  

会。服务端使用获取时区时间api拿到时区的时间避开服务器时间的影响。

 

大模型调用和多账号凭证

你简历中提到集成了讯飞星火大模型，说说怎么做的？

1.原先大模型调用是发送提问后能获取到文本、图片、ppt的回答。

2.获取文本答案实现形式是用户输入提问，将提问和用户的id作为内容发送websocket消息给服务端

服务端查询map中是否有和该用户绑定的大模型处理类对象，有则直接调用该大模型处理类对象的方法

没有则创建一个和该用户绑定的大模型处理类对象后调用方法然后再将该新建对象放入map

调用的方法会新建和大模型方的websocket连接，将提问内容存入该用户的历史问答集合，然后连带之前的问答历史记录作为websocket消息内容一起发送给大模型方

接收大模型方的websocket消息形式的回答后通过userid找到用户对应的websocket对象传递回客户端，然后将回答放入历史问答集合中

3.图片答案和ppt则是客户端发送http请求到服务端然后服务端通过发送http请求的形式获取大模型方响应并转发回客户端

虽然后端与讯飞星火方的交互被接口限制只能是websocket形式，但前后端交互在不采用websocket的前提下也可以采用http形式，然后前端建立和后端的sse连接，后端通知前端用sse做单向推送。

 

辅助记忆

1.集成后有什么功能

2.文本回答怎么实现

3.图片、ppt回答怎么实现

 

多账号凭证突破QPS为2的限制是如何做的？

1.每个账号可以申请一个有免费额度的key，而这个key对应文本、图片、ppt功能都各自有QPS为2的限制，也就是一个账号最多只能有2个人同时使用文生文或文生图、文生ppt功能，但各个功能间互不影响，彼此的使用人数互相隔离

所以若在2个人已经使用了文生文或文生图、文生ppt功能且都未 使用完毕的情况下第3个人使用该功能就会陷入阻塞状态直到前面2个人中有一个已经使用完毕

2.为了避免出现这种影响用户体验的情况于是用多个账号去扩充QPS上限，每个账号的每个功能都记录当前使用人数，当用户需要用到其中一个功能时则去账号集群中找该功能使用人数小于2的账号

使用该账号并将该账号的该功能使用人数加一，使用完毕后再将该账号的该功能使用人数减一

类似redis分布式锁的实现，以这种方式实现突破每个功能的QPS上限，若有两个账号则可以有4个人同时使用文生文或文生图、文生ppt功能，账号越多每个功能的QPS上限越大。

 

辅助记忆

1.qps为2的限制是什么意思

2.如何突破限制

3.突破方案的参考文献和突破效果

 

在通过存储多个账号凭证并在使用时查询使用后修改凭证状态的方式突破讯飞星火 QPS 为 2 的限制时，如何保证凭证管理的安全性和准确性？  

目前项目里凭证是存在后端程序里写死的

因此被攻破的概率不大，但如果凭证是存在redis中或文件中则可以进行加密存储

从存储的位置取出来拿到java程序中用时，java在进行一层解密，以此来保证凭证的安全性。准确性则是定期使用凭证，如果用某个凭证和大模型进行交互失败则说明凭证无法使用了，需要及时清理来确保凭证的准确性。

 

在高并发场景下，多个用户同时请求大模型服务，如何优化账号凭证的分配策略，确保每个用户都能尽快获得服务？

创建定时任务定期查询并得出可用列表，这样每次用户要使用时直接从可用列表里拿即可。

 

 

如果大模型功能调用过程中凭证过期了怎么办？

如果是图片或ppt功能这样一次性返回前端所有内容的，就切换其他可用凭证先在后端进行重试，若无其他可用凭证或其他可用凭证重试过程也失败了则响应通知前端请求失败，请稍后重试

如果是文本这样流式返回前端内容的则在后端返回响应给某个客户端前，先记录所有讯飞星火那边已经返回后端的响应内容，重试时在前端提问后面加上以及这是一部分回答请紧接这部分回答继续

确保呈现给前端的上下文连贯下去，若无其他可用凭证或其他可用凭证重试过程也失败了则响应通知前端请求失败，请稍后重试，并让前端将之前不完整的回答全清除。

数据同步

请你讲讲数据同步的流程？

1. mysql到es数据同步是把mysql的所有视频表、用户表的数据同步到es的视频索引和用户索引中。
2. （原先流程）每次对视频表、用户表的记录有影响的增删改操作执行时会远程调用消息队列的生产消息接口往同步消息的主题中推送增量消息，并在监听该主题的消费者中将增量消息缓存到redis
3. 使用xxl-job每十五分钟执行一次定时任务，该定时任务先查询redis中标识用户索引全量同步过的键值对是否存在，若不存在则说明未进行过全量同步
4. 先从mysql中查询用户表的所有数据，将所有数据导入es中，再向redis中存一个标识用户索引全量同步过的键值对，后续定时任务执行时就能查询到该键值对存在从而不再重复全量同步，视频索引也是同样步骤。
5. 全量同步逻辑后进行增量同步处理，从redis中取出对视频、用户表的增删改操作列表按先新增再删除再修改的顺序批量同步，同步时将单个的新增、删除、修改对象添加到批量处理对象中进行批量操作减少和es的交互，减轻es的负担，再递归的进行对es的批量操作
6. 每次批量操作时收集失败的单次新增或修改或删除操作，添加到一个新的批量处理对象中再去进行一次递归，直到不再有失败的单次操作，或者递归次数超过十次，这样最大程度防止失败，也能避免因特殊原因如es挂掉等导致一直失败，程序一直递归造成堆栈溢出问题。
7. 若超过十次还有失败的单次操作则将该失败操作记录到文件中且发送邮箱将该情况通知出去。
8. 同时先新增同步再删除同步后将最后剩下的文档id保存到hashset中，在将修改操作的单个操作对象添加到批量操作对象时，对每个修改操作对象都查询hashset，若判定该修改操作对象对应的文档id不存在hashset则说明这个文档也就是对应的那一行mysql记录的最终状态是被删除，那么就无需进行修改操作，也就无需将该修改操作对象添加到批量操作对象中，减少对es的操作，减轻对es的负担。
9. 但这样的话数据一致性不够强，会有延迟同步的情况，在对数据一致性要求高的业务场景下可以采用双写，在更新mysql的同时也更新es来做到强一致性，但这样做对服务器的负担会更重。或者每次定时任务执行时都直接查mysql数据库进行全量更新，这样实现简单，但表数据大的情况下会对数据库造成较大压力，或者引入canal实现，但引入canal需要额外部署中间件和增加新的依赖，复杂度变高了，而且自己实现有利于加深对技术的理解

 

辅助记忆

1.实现效果

2.增量消息缓存

3.全量同步判断

4.全量同步执行

5.增量同步执行

6.增量同步递归

7.递归防报错处理

8。为什么用hashset

9.双写、全量更新、canal优化方案和优缺点对比

 

 

随着数据量的不断增加，这种数据同步机制的性能是否会受到影响？你有什么优化思路来应对数据量增长带来的挑战？

全量只执行一次，因此优化主要在增量，可以把定时任务执行间隔时间变长来确保每次执行时处理的增量消息更多，可以采用多线程来并行对视频和用户的数据同步提升效率，同时还可以考虑提升服务器配置来应对数据量增长情况下性能变低的问题。

 

 

 

若Redis中的增量消息丢失（如Redis宕机），如何恢复未同步的数据？

先通过预先配置好的持久化方式恢复redis中的数据，再等待下一次同步，把未同步的数据同步上去。

 

如何保证增量同步操作的幂等性？例如，重复消费“新增”消息是否导致数据重复？

新增之前先查询是否该id，有的话就不新增 

 

如果程序中有多个定时任务，某个定时任务（本身）出错，怎么解决？

根据定时任务所在的完整链路进行问题的定位，定位后修改有误代码，同时修正错误代码已经造成了的对数据的影响，从日志中找到定时任务执行的原始数据，将错误数据修正成原始数据在正确代码逻辑下的最终正确数据。 

 

 

如果是在集群模式下多台服务器执行同一个任务，怎么保证任务执行的不重复性？

1.可以在mysql数据库中设计一张任务执行记录表，包含任务名，任务计划触发时间)等字段

并为这些字段创建唯一索引。当任务被触发时，尝试向该表插入一条记录。只有第一个成功插入的实例能继续执行，其他实例因为违反唯一约束而插入失败，从而知道自己不需要执行。任务执行完毕后，可以删除该记录，或者保留作为日志，但需要清理旧记录，优点:是实现相对简单，可利用现有数据库，缺点是 对数据库有一定压力。

2.还可以选择用Redis为当前任务实例生成一个唯一的 key，所有触发的实例set命令尝试执行设置一个30秒的锁，SET命令返回成功的实例获得了锁，可以执行任务。

其他实例收到失败响应，知道已有实例在执行，直接退出，获得锁的实例执行任务。

任务执行完毕后，主动删除 key ，可以使用 Lua 脚本保证原子性：先判断值是否是自己设置的，再删除。即使忘记删除或中途宕机，锁也会在过期时间后自动释放。

优点是性能高，比数据库锁通常更快。有现成的原子命令和过期机制。

缺点是Redis 的可用性和一致性需要考虑，特别是在主从切换或哨兵/集群模式下，可能存在锁丢失或误锁的风险。需要合理设置过期时间。

 

辅助记忆

1.数据库记录去重实现和优缺点

2.redis记录去重实现和优缺点

 

Mysql和es同步的数据有哪些？

用户表、视频表的数据。

 

为什么用户的数据也要同步到es？

因为有做聚合搜索功能，用户和视频都能进行搜索，因此用户数据也需要同步。

 

定时任务是通过扫描整个表来确定有没有全量同步过吗?

是通过全量同步后在redis中存键值对来确定有没有全量同步过的。但也可以搜索es中用户索引和视频索引，若能查出数据则说明进行过全量同步。

 

你的定时任务有没有防止出现错误的机制?

1.有采用多种机制来防止、检测和处理错误，以提高其健壮性和可靠性

单纯地“防止”所有错误是不可能的，但可以通过设计和实施良好的策略来最小化错误发生的概率，并在错误发生时有效地处理它们

在任务执行的核心逻辑代码块中使用try...catch捕获预期和意外的异常，并记录详细错误信息，当捕获到错误时，记录详细的日志，包括错误类型、错误消息、堆栈跟踪、发生时间、相关参数、任务的启动、关键步骤、完成状态以及执行耗时等，可以在出现问题时进行更好的对比和排查

2.还可以给任务设置一个合理的执行超时时间，如果任务执行时间超过阈值，可以强制终止它，防止单个任务卡死影响其他任务或耗尽系统资源

对于一些瞬时性错误如网络抖动、数据库连接暂时失败，可以配置自动重试策略，例如，延迟几秒/几分钟后重试，最多重试N次，在重试时逐渐增加等待时间，避免对下游系统造成持续压力

3.还有需要确保任务执行多次和执行一次产生的效果是相同的。这对于防止因重试或任务调度重叠导致的数据重复处理或状态错误很重要。

 

辅助记忆

1.声明只能最小化错误概率以及记录日志方案

2.给任务设置超时时间和重试策略

3.确保幂等性

 

失败处理那里，假如一直失败，会不会导致数据不一致，你是怎么解决的？

那就会同步失败，出现mysql和es数据不一致的情况，通过邮件或短信通知其他开发或运维过来处理。

 

 

如果通知人工不是最优的，现在要在系统内处理，保证一致性更高，你要怎么做呢？

如果一直失败的话且需要保证一致性足够高的话可以将mysql中对应的增量回滚来保证一致性足够高，这样的话需要针对不同类型的增量额外记录一份信息，新增类型的增量回滚，需要额外记录新增的mysql记录的id用于删除，删除和修改类型的增量回滚则需要保存被删除前或被修改前的记录具体内容来增加被删除了的数据或复原被修改了的数据。

 

 

同步为什么要用redis不直接用MQ接ES？

因为需要每隔一段时间进行批量同步，redis可以做一个缓存功能，缓存一段时间内的增量消息。

 

搜索部分是直接调es吗?

是的，在搜索服务利用es的multimatchquery查询api编写接口，并在视频服务中远程调用搜索服务的api。

 

数据同步批量修改如何保证顺序性？

1.在完整流程中能想到的批量修改乱序有两个情况

一个是在mq中消费增量同步消息时，对同一个视频或用户的多个修改的消息出现了乱序，修改时间靠后的修改操作对应的增量消息反而被先消费存到Redis中，导致在Redis存储修改增量的列表中时间戳靠后的修改操作的顺序反而靠前

那么假设一个视频被修改了两次，同步时数据的最终状态就不是最后一次修改而是第一次修改，这样就会出现乱序

2.还有一个是同步时会有对失败的增量同步进行递归重试的步骤，如果消费增量同步消息无误，同一个视频或用户的多次修改操作也有可能出现时间戳靠前的修改操作失败了，但时间戳靠后的修改成功了，然后重试时间戳靠前的修改操作，导致数据的最终状态并不和mysql中一致

2.这两种情况都可以通过修改缓存到Redis的修改增量的结构来保证顺序性，向修改增量的结构中添加一个时间戳，取修改增量进行批量修改时按用户或视频进行聚合，同一个用户或视频的修改增量按时间戳排序进行数据同步

4.让对同一个用户或视频的多个修改操作达成原子性，要么全部成功要么全部失败，防止出现脏数据，这种方案可以保证数据同步批量修改的顺序性，但和es的交互更多，对es的负担更大，需要权衡顺序性和服务器减轻负担的优先级。

 

辅助记忆

1.出现乱序的情况一，redis里存储的增量顺序乱了

2.乱序情况二，重试同步过程导致乱序

3.聚合同一个视频或用户的增量消息来批量消费确保不乱序

4.达成的效果和优缺点

 

为什么不直接把数据存到es，而是要存mysql里？

Mysql有相比es更加完善的事务机制来保持数据操作的一致性，以及更强大的数据备份和恢复能力，因此需要在mysql中也存一份数据。

 

 

数据同步的时候如果es挂掉一段时间之后重启，会重新全量同步吗？

不会，因为全量同步只进行一次。

 

为什么要设计数据同步和合并请求？

平时学习时比较追求方案的升级和优雅的实现，因此设计数据同步和合并请求这两个流程。

 

合并请求

请你讲讲合并请求的流程？

1. 合并请求是在某些请求的流量低于阈值时保持原先请求路径，在流量高于阈值时转向新请求路径，且该路径对应接口做了合并统一处理然后再统一返回的方式，以此来减少对数据库的压力，加快高并发环境下的响应速度。
2. 实现方式是程序启动后执行定时任务，初始化要判断是否需要合并请求的接口的qps值为0，后续每1s重置一次qps值然后请求进入网关后判断请求路径是否是需要考虑合并请求的路径，是的话查询该请求的qps值是否大于等于临界值，大于等于就将请求路径转成合并请求路径，否则保持原先的单独查询不变，再将该请求的qps值加一
3. 进入合并请求接口会创建一个自定义请求对象，属性包含唯一的请求id、用户id和一个completablefuture对象，再将该对象放入Linkedblockingqueue队列中，然后调用completablefuture的get方法阻塞当前线程，同时在Springboot程序启动后会初始化一个每隔500ms执行一次的定时任务，每次定时任务执行时会将缓存在队列中的自定义请求对象取出来，根据这批自定义请求对象的用户id组成的集合进行批量查询，查询结果转换成请求id为键用户信息为值的形式，再遍历之前取出来的自定义请求对象集合，通过调用completablefuture的complete方法，将对应每个自定义请求对象的请求id的用户信息填充到completablefuture对象中，然后该次请求对应被阻塞的线程也会被唤醒并返回用户信息给前端。
4. 但这样有一个缺陷，completablefuture常用的get方法没有超时机制，因此若过长时间没有拿到查询结果就会一直阻塞
5. 因此优化方案是返回前端的形式由指定completablefuture类型为用户对象类型再调用get方法等待用户对象被填充后返回前端，换成指定Linkedblockingqueue类型为用户类型，再监听Linkedblockingqueue中的数据，原先的自定义请求对象的completablefuture换成Linkedblockingqueue，查询后对每个自定义请求对象也就是每一次的请求都进行一次填充用户对象到completablefuture的操作也换成对每个自定义请求对象都进行一次填充用户对象到Linkedblockingqueue中，一旦自定义请求对象中的队列有数据就代表查询结果已经被放入，返回前端用户信息，设置队列超时时间为3s，超过三秒某次请求对应的队列中还无数据则会直接放弃阻塞线程，返回null给前端。也可以用get方法的可传入超时时间的重载方法，等待时间超过该方法的传参值后会抛出异常，捕获该异常并返回null给前端。
6. 这里临界值的确定可以先通过用户调研得到一个用户比较难接受的平均响应时间，然后进行压力测试找到响应时间会慢到该平均响应时间的qps值，用这个qps值作为临界值。同时不全部走合并请求的原因是合并请求的查询定时任务被设置为500ms，防止设置的过短对数据库压力大，那么如果低并发的情况单次查询速度可能比合并请求后批量查询速度更短，而且低并发对数据库压力也不算大，不用考虑为了降低数据库压力而合并请求的情况，也就没必要合并请求。

 

辅助记忆

1.合并请求是做什么

2.请求是否需要走合并请求逻辑

3.使用completablefuture的形式合并请求如何做

4.completablefuture方式的缺陷

5.换成linkedblockingqueue和get重载方法怎么做

6.临界值qps如何确定

 

统计qps还有别的方法吗？

可以用sentinel进行qps统计，好处是有现成api可以省去自己执行定时任务重置qps和网关中累加qps，坏处是引入了额外的依赖增加了系统的复杂度，需要考虑引入sentinel对系统原先模块造成的影响来衡量是否自己实现qps统计。

 

定时任务用的什么？

XXl-job，也可以用Spring自带的注解或者定时任务线程池，后两者简单易使用但功能相对单薄，而XXl-job虽然配置更复杂但有单独的ui界面可以在界面做配置，能和代码形成一定程度的解耦，同时日志记录详细，可以更方便的追踪任务的执行状态和结果。

 

哪些请求需要（可以）被视为高并发情况下要做合并的请求？

这个合并请求方案关键是将sql的where改成in来批量查询，因此类似获取用户信息、获取视频信息这种传参是实体id的接口都可以。

 

合并请求流程是怎么想到的？

考虑到项目的场景会涉及到高并发，因此提问ai后得到多条应对思路，从其中选择合并请求这一条，再自己慢慢完善合并请求的完整过程。

 

写这个流程时有遇到什么困难？

一开始实现细节有多种思路，因此会对多种思路做比较，比如自己实现统计qps时是用定时任务还是请求进网关后才开始统计qps，多番对比得到最终方案。

 

还有哪些可以应对高并发的方案？

整体思路一是在不改变现有处理能力的情况下拒绝超出处理能力范围的请求，对超出阈值的请求进行限流或者熔断降级处理

二是提升现有处理能力，增加服务器配置，部署多个实例进行负载均衡

然后优化慢sql和在合适的列上创建索引提升查询速度

分库分表将数据分散到多个数据库或表中和读写分离来提升数据库的写入和查询速度

然后可以将热点数据缓存到redis中减少对数据库查询，减小数据库压力和增加响应速度，以及可以将一部分工作放到子线程中异步进行来提升请求的响应速度。

 

唯一请求id是如何生成的？

用的uuid生成的，如果考虑id重复的可能性也可以优化，在原先的uuid后面加上请求的时间戳来进一步降低id重复的概率。

 

 

Completablefuture有哪些常见用法？

执行有返回值的异步任务，执行无返回值的异步任务，阻塞当前线程直到调用complete方法（主线程中调用get方法阻塞的就是主线程，子线程中调用get方法阻塞的就是子线程）

 

综合性

请介绍整个系统后端的架构设计，有哪些模块以及各模块的作用和各模块之间的关系？

总共六个业务服务，一个公共服务，六个业务服务分别是网关服务，视频服务，聊天与大模型服务，消息服务，用户服务，搜索服务

网关服务

作为请求入口，接收请求后除非登录注册请求，其他请求一律经过鉴权后路由转向到其他服务，鉴权不通过则返回401状态码，登录后授权，定时刷新token权限

视频服务

视频的分片上传与断点续传，视频的点赞评论弹幕收藏创建收藏夹

聊天与大模型服务

一对一实时私聊，大模型文生文文生图文生ppt

消息服务

点赞、评论、私聊、关注up动态消息的生成和消费，数据同步增量消息存到redis

用户服务

用户信息查看编辑，用户个人主页权限查看编辑

搜索服务

推荐视频，视频和用户的条件搜索，关键字补全和高亮，数据同步执行

公共服务

存放可复用类，如mybatis-plus的特定类和openfeign接口类，全局异常处理器，mybatis-plus自动填充器，泛型响应类，自定义序列化器

各模块之间的关系是通过openfeign互相调用。

 

什么是微服务架构？它有什么优点？为什么在项目中选择使用微服务？

微服务架构是一种将单个应用程序开发为一组小型、独立的服务的架构方法，每个服务都可以独立地进行开发、部署和扩展，这些服务通过轻量级通信机制（如 HTTP/REST）进行交互，共同构成一个完整的应用系统。

微服务架构的优点

高可扩展性，每个微服务可以根据其自身的负载需求独立地进行扩展。例如，在电商项目中，订单服务在促销活动期间可能需要处理大量订单，可单独对订单微服务进行扩展，增加服务器资源，而不会影响到其他服务，如用户服务、商品服务等。

敏捷开发与部署，各个微服务可以由不同的团队独立开发、测试和部署，加快了开发和迭代速度。不同微服务可以根据实际需求选择最合适的技术栈，提高开发效率。

高可靠性，当某个微服务出现故障时，只会影响到该服务本身，不会导致整个系统崩溃。系统的其他部分仍然可以正常运行，提高了系统的稳定性和可靠性。例如，在社交媒体系统中，若图片处理微服务出现问题，用户仍然可以正常浏览动态、发送消息等。

易于维护和升级，每个微服务的功能相对单一，代码量相对较小，维护起来更加容易。当需要对某个功能进行升级或修改时，只需要关注对应的微服务，降低了维护成本和风险。

可以应对复杂业务需求，将复杂业务拆分成多个简单的、可管理的微服务，每个微服务负责一个特定的业务功能，使项目结构更加清晰，便于理解和管理。

 

你在项目中是如何设计库表的？可以从字段、索引、关联等方面回答？

根据有哪些实体、对实体的动作和实体与实体间的关系建的，如有视频实体和用户实体就建视频表和用户表，有对视频的点赞、评论操作就建立点赞表和评论表，有收藏夹和视频且是多对多关系就额外建一个收藏表做中间表。

 

为什么要做这个项目？做之前有调研过其他同类产品吗？

这个项目是在牛客上看到的开源项目，做这个项目是因为有用到目前主流Java企业开发技术栈如各大微服务组件SpringBoot这些，有相较于其他单体或微服务项目来说更加复杂的业务和流程，也有充足的可供扩展设计的空间，熟练掌握后能有效提升代码能力、理解需求能力和根据需求制定和抉择技术方案的能力，这样进入公司后所需适应时间就会比较短，公司的培养成本也会比较低。有调研过，综合比较最能综合提升多方面能力的还是这个项目，因此选择了这个项目。

 

功能是如何划分到各服务的？

按几个重要的实体去划分，和权限相关的登录注册以及授权鉴权等功能都划到统一处理权限的网关服务，和用户相关的操作如修改用户信息、修改个人主页权限和关注用户等都划到用户服务，和视频相关的操作如上传点赞评论弹幕收藏等都划到视频服务，和消息队列中的消息有关的如各主题消息的生成与消费，未读消息数量和未读消息内容查询等都划到消息服务，和搜索结果相关的如关键字搜索、关键字补全、数据同步等都划到搜索服务，和聊天消息有关的如聊天会话的增删改查、聊天消息的增删改查和聊天消息的实时传递、和大模型的聊天等都划到聊天服务。

 

项目中遇到的最大的困难？

理解项目后去思考技术实现是否可以有其他方式，实现方案的优劣，以及技术栈的使用原因和技术栈对比，比如思考项目中数据同步是否需要使用Rocketmq，结论是不用可以省去一个步骤，但不能统一的在消息队列中记录日志追踪缓存增量消息情况，也不能利用消息队列的重试机制增加一层保障，就得自己手动添加重试机制防止缓存增量消息到redis失败。

 

你的视频平台相对于bilibili的区别是什么?

数据量更小，功能没有bilibili那么多，但也加了一些bilibili没有的功能如集成大模型。

 

介绍下视频平台?

本项目仿照bilibili，旨在提供一个前后端分离的视频平台，实现了多种方式注册登录、视频的上传、点赞、收藏、弹幕、评论、个人主页内容与权限的编辑查看、聚合搜索、私聊与大模型文生文、文生图、智能ppt等功能

 

为什么有这么多性能优化的思考？

觉得性能优化是实习工作中除去接口实现外，必不可少的步骤，因此在学习过程中有意识的设计和改进性能优化方案。

 

Mysql表有哪些？

视频、视频数据、用户、点赞、点赞通知、评论、评论通知、收藏夹、收藏、弹幕、聊天消息、聊天会话、历史播放、用户权限。

如何记住这些表？

项目中的实体有视频、用户、收藏夹，因此有对应的视频用户收藏夹表，而对这些实体的操作有点赞、评论、弹幕、收藏、关注、播放，因此有对应的表，同时因为视频和收藏夹的关系是多对多，一个视频可以在多个收藏夹中，一个收藏夹也可以有多个不同的视频，有中间表，中间表即为收藏表，将视频数据存到表里可以减少每次查询视频时对点赞评论弹幕的聚合查询，因此有额外的视频数据表，用户可以设置自己的个人权限因此有用户权限表，有后台消息通知因此有点赞通知和评论通知表，用户可以创建会话和在某个会话中和其他用户聊天，因此有聊天会话表和聊天表。

 

项目中用到了哪些设计模式？

没有特意去写设计模式实现，但了解一些常用的设计模式

如工厂模式，工厂模式是一种创建型设计模式，其核心思想是将对象的创建和使用分离，把对象创建逻辑封装在一个工厂类中，让使用者无需关心对象具体的创建过程，只需向工厂请求所需对象即可

这样做能提高代码的可维护性和可扩展性，优点是解耦对象的创建和使用，使用者只需关注如何使用对象，无需了解对象的创建细节，降低了代码的耦合度，便于维护和扩展

当需要修改或新增产品时，只需在工厂类中进行相应的修改或扩展，不会对其他部分的代码产生影响

缺点是代码复杂度增加，引入工厂类会增加代码量和复杂度，特别是在简单场景下，使用工厂模式可能会显得过于繁琐，以及如果工厂类负责创建多种类型的产品，可能会导致工厂类的职责过重，违反单一职责原则。

 

对ai有多少了解？

当前比较火的方向是ai应用层开发，集成大模型api来实现各种功能，其中一个热门功能就是实现agent智能体，而agent代表着具备自主决策、环境交互和目标导向能力的智能系统，相比普通ai更接近人，有一套融合感知、规划、行动和学习的综合架构，有更强的自主性。

 

技术选型

项目中为什么要使用Redis？

Redis的应用场景有缓存热点数据减小数据库压力、存放一些无需持久化的数据、排行榜/计数器、发布/订阅、分布式锁、队列、存储地理位置信息，而项目中有数据同步的模块需要缓存增量信息，有验证码需要暂存，因此用到了redis。

 

 

 

项目中为什么要使用Websocket？

Websocket适用于需要保持服务端与客户端双向通信或服务端主动通知客户端或需要低延迟的场景，而项目中私聊需要实时也就是低延迟的消息通信，同时私聊架构是客户端向服务端发websocket消息并由服务端主动通知另一个客户端，因此采用websocket。若要采用sse技术则需要修改前后端交互格式，前后端建立sse连接，一个客户端向另一个客户端发送消息采取向服务端发送请求服务端再通过sse连接向另外一个客户端主动推送消息的形式。

 

项目中为什么要使用Minio？

Minio适用于有存储文件需求的场景，文件的上传下载性能更高，且可以方便的登录控制台查看和编辑文件，而项目中若采用mysql保存文件流会出现查询速度慢、容易出现数据库I/O瓶颈、存和取文件还需要额外转换格式等问题，因此选择对象存储服务，minio相较oss来说定制性更强，数据主权和控制权更大，但当前项目暂时没有这方面的需求，选择minio的关键原因是可以省钱。

 

项目中为什么要使用Mybatis-plus？

便捷执行单表增删改查

减少代码量

代码可维护性高

 

项目中为什么要使用Nacos？

微服务间通信需要一个服务发现与注册中心来方便服务间的互相调用

 

项目中为什么要使用Gateway？

可以作为唯一请求入口，统一鉴权与授权实现单点登录

 

 

项目中为什么要使用XXL-JOB？

XXL-JOB是一个分布式定时任务框架，天然支持分布式，可以页面配置定时任务，与代码解耦，且可以很方便查看执行的任务的日志，也能看到执行是否成功和失败，还有统计功能，而项目中有数据同步、QPS重置、定期批量处理合并请求需要定时任务，因此使用了XXL-JOB。

 

 

 